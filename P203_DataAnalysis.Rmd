---
title: "P203 Subjective Perception and ERP Amplitude (the N170)"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output:
  html_document:
    df_print: paged
    number_sections: true
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: false
    includes:
      after_body: Utilities/footer.html
---

# General introduction

## Introduction

**Linear Mixed Model** were used.

## Experiment design

* **Independent variables**:
+ Stimulus Type (`Type`: *intact* vs. *scrambled*)
+ Stimulus Category (`Category`: *faces* vs. *houses*)
+ Hemisphere (`Hemisphere`: *left* vs. *right*)
+ Duration (`Duration`: *17* vs. *200*)


## Preparations
```{r, echo=FALSE, include=FALSE}
# knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(echo = TRUE) # show the code for this chunk
options(width = 130)  # set the maximum width of the html output
```

```{r setup and load the related libraries, message=FALSE}
## load libraries
library(tidyverse)
library(magrittr)
library(lme4)
library(lmerTest) 
library(emmeans)

# options for calculating estimated marginal means
# lmer.df = c("kenward-roger", "satterthwaite", "asymptotic")
emm_options(lmer.df = "satterthwaite", 
            lmerTest.limit = 1e6,
            opt.digits = FALSE)  # , pbkrtest.limit =, disable.pbkrtest = FALSE

```

```{r foldes and load R files, include=FALSE}
set.seed(42)

# folders
folder_R <- "R"
folder_data <- "data"
folder_nesi <- "NeSI"
folder_bmm <- "bmmfit"

# load all the R files
sapply(list.files(folder_R, "*.R", full.names = TRUE, recursive = TRUE), source)

```

```{r settings}
# general setting
saveCSV <- FALSE
ratio_count <- 0.8
RT_min <- 200

# set up the theme for plot and rainclound plot
plot_theme <- {
  general_theme +
    theme(legend.position = "right")
}

erp_theme <- {
  general_theme +
    theme(legend.position = "bottom")
}

ylimit_p1 <- c(2.5, -0.5)
ylimit_n170 <- c(1.5, -5.5)  # y axis for plotting N170 amplitude

resp_labels = c("sure faces", "not sure faces", "guessing", "not sure houses", "sure houses")

```


# Hypotheses
Previous studies showed that the N170 amplitudes evoked by faces preseneted for longer durations were larger:
```{r}
Duration <- c("17", "200")
Amplitudes <- c(-2.5, -5)
Hypotheses <- rep("means", 2)

df_lit <- data_frame(Duration, Amplitudes, Hypotheses)

plot_lit <- {
  ggplot(data = df_lit, aes(y = Amplitudes, x = Duration, fill = Duration)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(color = "black") +
    facet_grid(. ~ Hypotheses) +
    scale_fill_manual(values = c(gray(.7), gray(.3))) +
    scale_y_reverse(limits =c(0, -5.5), breaks = seq(0, -5, -1), expand= c(0, 0)) +  # set the limit for y axis
    geom_hline(yintercept = -2.5, linetype = "dashed", color = "red", size = 1) +
    labs(x = "", y = expression(paste("Amplitudes (", mu, "V)"))) +  # set the names for main, x and y axises ,  title = "Means", 
    # theme_bw() +
    general_theme +
    theme( # strip.text = element_text(color = "white"),
      legend.position = "none",
      axis.line = element_line(size = 3, colour = "black"))
}

plot_lit
```

There are two possible explainations for the aggregated mean amplitudes:
```{r}

Duration <- rep(c(rep("17", 5), rep("200", 5) ), 2)
Amplitudes <- c(c(rep(-2.5, 5), rep(-5, 5)), c(rep(-.83, 3), rep(-5, 7)))
TrialNum <- rep(as.character(rep(c(1:5), 2)), 2)
Hypotheses <- c(rep("Possibility 1", 10), rep("Possibility 2", 10))

df_st <- data_frame(Duration, Amplitudes, TrialNum, Hypotheses)

plot_st <- {
  ggplot(data = df_st, aes(y = Amplitudes, x = Duration, fill = Duration, color = TrialNum)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge") +
    scale_fill_manual(values = c(gray(.7), gray(.3))) +
    scale_color_manual(values = rep("black", 5)) +
    facet_grid(. ~ Hypotheses) +
    geom_hline(yintercept = -2.5, linetype = "dashed", color = "red", size = 1) +
    scale_y_reverse(limits =c(0, -5.5), breaks = seq(0, -5, -1), expand= c(0, 0)) +  # set the limit for y axis
    labs(x = "Duration (ms)") +  # set the names for main, x and y axises , title = "At the single-trial level:", , y = expression(paste("Amplitudes (", mu, "V)"))
    theme_bw() +
    general_theme +
    theme(legend.position = "none",
          axis.title.y = element_blank(),
          axis.line = element_line(size = 3, colour = "black"))
}

plot_st
```


```{r combine the aggregated mean amp plots and the explanation plots, include=FALSE}

# library(ggpubr)
# plot.hypo <- ggarrange(plot_lit, plot_st, widths = c(1.1, 4))
# 
# # ggsave('plot_hypo.pdf', plot.hypo, width = 7, height = 3)
# 
# plot_hypo
```


# Behavior results
```{r load behavioral results of 205}
raw_beha_205 <- {
  "E205_35_Behavior.csv" %>% 
    file.path(folder_data, .) %>% 
    read_csv() 
}

```


```{r select certain rows and columns from the data, and calculate the Z value for reaction times (205)}
clean_beha_205 <- {
  raw_beha_205 %>%
    filter(`Procedure[Trial]` == "expProc") %>% # remove rows for practice and countdown
    select(ExperimentName, SubjCode = Subject, blockID, Block, Trial, Age, Sex, Handedness, Type = `stimCategory[Trial]`, Category = `FH[Trial]`, Duration = `stimDuration[Trial]`, ACC = `Resp.ACC[Trial]`, Resp.RT = `Resp.RT[Trial]`, Resp = `Resp.RESP[Trial]`, Stimuli = `stimName[Trial]`) %>% # select and rename the columns (remove unuseful columns)
    mutate(
      SubjCode = factor(paste("P", SubjCode, sep = "")), # save SubjCode as factor
      Type = substr(Type, 1, 1),
      Type = recode_factor(Type, "N" = "intact", "S" = "scrambled"), # rename the levels of Type
      Category = recode(Category, "hosue" = "house", "house" = "house", "face" = "face", .default = "face"), # rename "hosue" as "house"
      Duration = factor(Duration), # save Duration as factor
      Category = as.factor(Category),
      Resp = as.factor(Resp),
      blockID = as.factor(blockID)
    ) %>% 
    group_by(SubjCode, Type, Category, Duration, ACC) %>% # divide the data based on these conditions
    mutate(
      RT = Resp.RT + as.numeric(levels(Duration))[Duration],
      RT.Z = scale(RT), # calculate the Z value for reaction times within each group
      RT.Within3Z = ifelse(RT.Z <= 3 & RT.Z >= -3, 1, ifelse(RT.Z < -3 | RT.Z > 3, 0, NaN)) # if the Z values are between -3 and 3, will be marked as 1
    ) %>% 
    ungroup() # ungroup the data 
  
}

# behavior.tidyup
head(clean_beha_205, 10)

```

```{r check the number of trials for 205}
# check the number of trials for 205
sum.count.205 <- {
  clean_beha_205 %>% 
    group_by(SubjCode, Type, Category, Duration) %>% 
    summarize(Count_sum = n())
}

valid.count.205 <- {
  clean_beha_205 %>% 
    filter(RT > RT_min) %>% 
    group_by(SubjCode, Type, Category, Duration) %>% 
    summarize(Count = n()) %>% 
    right_join(sum.count.205, by = c("SubjCode", "Type", "Category", "Duration")) %>% 
    mutate(ratio = Count / Count_sum) %>% 
    filter(ratio > ratio_count) %$%
    SubjCode %>% 
    unique()
}

# remove the participants
clean_beha_205 %<>% filter(SubjCode %in% valid.count.205)

```


```{r remove participants whose performance in Key 1 was lower than 95%}
# remove participants whose performance in Key 1 was lower than 95%

valid.17 <- {
  clean_beha_205 %>%
    filter(Duration == 17, Resp == 1) %>% # Type == "intact",
    group_by(SubjCode, Duration, Resp) %>% # Type, 
    summarize(Accuracy = mean(ACC), Count = n()) %>% 
    filter(Accuracy > 0.95) %$%
    SubjCode
}


# clean_beha_205 %>%
#   filter(Duration == 17, Resp == 1) %>% # Type == "intact",
#   group_by(SubjCode, Duration, Resp) %>% # Type, 
#   summarize(Accuracy = mean(ACC), Count = n()) %>% 
#   filter(Accuracy < 0.95) %>% 
#   ungroup() %>% 
#   summarize(mean(Accuracy), min(Accuracy), max(Accuracy))  

clean_beha_205 %<>% filter(SubjCode %in% valid.17)



```

## Participant demographic information
```{r participant information E205}
subj.info.205 <- {
  clean_beha_205 %>% 
    select(SubjCode, Age, Sex, Handedness) %>% # select the columns of participant inforamtion
    distinct() # only keep the unique rows
}

subj.info.205

```

```{r}
mean(subj.info.205$Age)
range(subj.info.205$Age)

sum(subj.info.205$Sex == "female")
```


## Responses
```{r}
tmp.count <- {
  clean_beha_205 %>% 
    group_by(SubjCode, Type, Category, Duration) %>% 
    summarize(Count_sum = n())
}


avg.dist.long.205 <- {
  clean_beha_205 %>% 
    # mutate(RespRateFace = if_else(Category == "face", ACC, if_else(Category == "house", as.numeric(!ACC), NaN))) %>% 
    group_by(SubjCode, Type, Category, Duration, Resp) %>% 
    summarize(Count = n()) %>% 
    
    right_join(tmp.count, by = c("SubjCode", "Type", "Category", "Duration")) %>% 
    mutate(RespRate = Count / Count_sum) %>% 
    ungroup()
}


# descriptive statistics of accuracy for plotting
desc.dist.205 <- {
  avg.dist.long.205 %>%
    group_by(Type, Category, Duration, Resp) %>%
    summarize(Mean = mean(RespRate)
              , N = n()
              , SD = if_else(N > 1, sd(RespRate), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI_lo = Mean - SE * 1.96
              , CI_hi = Mean + SE * 1.96
              , Median = median(RespRate)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>% 
    ungroup() %>% 
    add_row(Type = "intact", Category = "house", Duration = 200, Resp = 2, Mean = 0, N = 0, SD = 0, SE = 0, SE.lo = 0,
            SE.hi = 0, CI_lo = 0, CI_hi = 0, Median = 0, Lower = 0, Upper = 0)
}

avg.dist.wide.205 <- {
  avg.dist.long.205 %>% 
    mutate(Conditions = paste(Type, Category, Duration, Resp, sep = "_")) %>% 
    select(SubjCode, Conditions, RespRate) %>% 
    spread(Conditions, RespRate)
}


```


```{r rainclound plot of the RT data E205, warning = FALSE}
knitr::kable(desc.dist.205, digits = 4)

dist.RainPlot.205 <- {
  ggplot(data = avg.dist.long.205, aes(y = RespRate, x = as.factor(Resp), fill = Category)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RespRate, color = Category), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RespRate), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.dist.205, aes(y = Mean, x = Resp, color = Category), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.dist.205, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(Type ~ Duration) +
    
    # facet_grid(. ~ Type, switch = "x") +  # create two panels to show data
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") + # palette = "RdBu"
    # scale_fill_brewer(palette = "Set1") + # palette = "RdBu"
    labs(title = "Reaction times for 205", x = "Stimulus Type", y = "Reaction times (ms)", fill = "Duration(ms)", color = "Duration(ms)") +  # set the names for main, x and y axises and the legend
    # scale_x_discrete(labels=resp_labels) +
    # coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot for reaction times}
dist.RainPlot.205
```


```{r}

dura.labels <- c("17ms", "200ms")
names(dura.labels) <- c(17, 200)

dist.ColuPlot.205 <- {
  ggplot(data = desc.dist.205, aes(y = Mean, x = Resp, fill = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Type ~ Duration,
               labeller = labeller(Duration = dura.labels)) +
    geom_errorbar(mapping = aes(ymin = CI_lo, ymax = CI_hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "", x = "Responses", y = "Percentage", fill = "Category") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    erp_theme
}

dist.ColuPlot.205

```


```{r}
df.ratio.205 <- {
  clean_beha_205 %>%
    mutate(isFace = if_else(Category == "face", 1, 0)) %>%
    group_by(SubjCode, Type, Duration, Resp) %>%
    summarize(ratio = mean(isFace), Count = n())
}

desc.ratio.205 <- {
  df.ratio.205 %>%
    group_by(Type, Duration, Resp) %>%
    summarize(Mean = mean(ratio)
              , N = n()
              , SD = if_else(N > 1, sd(ratio), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI_lo = Mean - SE * 1.96
              , CI_hi = Mean + SE * 1.96
              , Median = median(ratio)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>%
    ungroup()
}

```



```{r eval=FALSE, include=FALSE}

# rate.ColuPlot.205 <- {
#   ggplot(data = desc.ratio.205, aes(y = Mean, x = Resp)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
#     geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
#     facet_grid(Type ~ Duration) +
#     geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
#                   show.legend = FALSE, width = 0.25, alpha = .5,
#                   position = position_dodge(width=0.9)) +
#     geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
#     coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
#     scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
#     labs(title = "", x = "Responses", y = "Percentage") +  # set the names for main, x and y axises Subjective Responses for E205
#     scale_fill_grey() +  # set the color for columns
#     # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
#     plot_theme
# }
# 
# rate.ColuPlot.205

```




```{r eval=FALSE, include=FALSE}
# df.erp.SC.205 %>%
#   filter(Component == "N170", Hemisphere == "Right") %>%
#   group_by(SubjCode, Category, DuraConf) %>%
#   summarize(count = n()) %>%
#   mutate(conditions = paste(Category, DuraConf, sep = "_")) %>%
#   ungroup() %>%
#   select(SubjCode, conditions, count) %>%
#   spread(conditions, count)
```

### LMM for responses
```{r}
df.ratio.205 %<>% sdif_coding_P203_resp 
```

#### The maximal model
```{r}

lmm.max.resp <- lmer(ratio ~ Type * Duration * Resp + (1 + Type_C + Dura_C + Type_Dura | SubjCode), 
                     df.ratio.205)

print(summary(lmm.max.resp), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r}

lmm.zcp.resp <- update(lmm.max.resp, 
                       formula = ratio ~ Type * Duration * Resp + 
                         (1 + Type_C + Dura_C + Type_Dura || SubjCode))

print(summary(lmm.zcp.resp), corr = FALSE)

```

#### The reduced model
```{r}
summary(rePCA(lmm.zcp.resp))


lmm.rdc.resp <- update(lmm.zcp.resp,
                       formula = ratio ~ Type * Duration * Resp + 
                         (0 + Dura_C + Type_Dura || SubjCode))

anova(lmm.rdc.resp, lmm.zcp.resp, refit = FALSE)

```

#### The extended model
```{r}

lmm.etd.resp <- update(lmm.zcp.resp,
                       formula = ratio ~ Type * Duration * Resp + 
                         (0 + Dura_C + Type_Dura | SubjCode))

summary(lmm.etd.resp)

```


```{r}

lmm.etd1.resp <- update(lmm.etd.resp,
                        formula = ratio ~ Type * Duration * Resp + 
                          (0 + Type_Dura | SubjCode))

summary(lmm.etd1.resp)

```


```{r}
anova(lmm.etd1.resp, lmm.rdc.resp, refit = FALSE)
```

#### The optimal model
```{r}
lmm.opt.resp <- lmm.etd1.resp 

summary(lmm.opt.resp)
```

### Estimated marginal means
```{r}
emm.resp <- emmeans(lmm.opt.resp, ~ Resp + Duration + Type)

as.data.frame(emm.resp) %>% 
  select(Type, Duration, Resp , everything())
```

### Plots
```{r}

resp.ColuPlot.205 <- {
  ggplot(data = as.data.frame(emm.resp), aes(y = emmean, x = Resp)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Type ~ Duration, 
               labeller = labeller(Duration = dura.labels)) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    # coord_cartesian(ylim = c(0,1.12) ) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0), limits = c(-0.1, 1.15), breaks = seq(0, 1, 0.25)) +  # remove the space between columns and x axis
    labs(title = "", x = "Responses", y = "Percentage") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    plot_theme
}

resp.ColuPlot.205

```


### Contrasts
```{r eval=FALSE, include=FALSE}
# contra.resp <- contrast(emm.resp, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# 
# contra.resp
# confint(contra.resp)
```


```{r}
contra.resp <- contrast(emmeans(lmm.opt.resp, ~ Duration | Resp + Type), "pairwise")

contra.resp[c(1, 5)]
confint(contra.resp[c(1, 5)])
```

### One-sample t-test
```{r}
test(emm.resp, null = 0.5)

```


# ERP amplitude analysis
## Load mean amplitude for single trials
The raw mean amplitude of each trial for all participants were loaded.
```{r load trial mean amplitude E2, message = FALSE}
# read the trial mean amplitude data
df.erp.E2 <- {
  "E205_MeanAmp.csv" %>% 
    file.path(folder_data, .) %>% 
    read_csv() %>% 
    substr_Event() %>% 
    filter(SubjCode %in% valid.17) %>% 
    mutate(SubjCode = as.factor(SubjCode),
           Hemisphere = as.factor(Hemisphere),
           urResponse = as.factor(urResponse),
           Stimuli = substr(stimName, 2, 6))
}

df.erp.E2 %>% 
  group_by(SubjCode, Stimuli, Hemisphere, Type, Category, Duration) %>% 
  summarize(count = n())

```

## Linear mixed model across responses

### Set the successive difference coding
```{r set the dummy coding for ERP data E2}
# dummy coding
df.erp.E2.all <- sdif_coding_P203_erp(df.erp.E2)
```


### Amplitudes of the P1
```{r erp df for the P1 E2}
# only keep the data for amplitudes of the P1 (correct and incorrect erps)
df.erp.P1.E2 <- {
  df.erp.E2.all %>% 
    filter(Component == "P1")
}

if (saveCSV) {
  output.erp.P1.E2 <- file.path(folder_nesi, "E205_erp_P1.RData")
  save(df.erp.P1.E2, file = output.erp.P1.E2)
}

# the structure of this dataset
head(df.erp.P1.E2, 10)
```


#### The maximal model
```{r maximal lmm for P1 E2}
file.max.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_max.RData")

# fit the maximal model
if (!file.exists(file.max.P1.E2)) {
  lmm.max.P1.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere +
                          (1 + Type_C + Cate_C + Dura_C + Hemi_C +
                             Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                             Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi +
                             Type_Cate_Dura_Hemi
                           | SubjCode) +
                          (1 + Type_C + Dura_C + Hemi_C +
                             Type_Dura + Type_Hemi + Dura_Hemi +
                             Type_Dura_Hemi
                           | Stimuli),
                        data = df.erp.P1.E2,
                        verbose = TRUE,
                        control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                              optCtrl = list(maxfun = 1e7)))
} else {
  load(file.max.P1.E2)
}

print(summary(lmm.max.P1.E2), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r zcp lmm for P1 E2}
file.zcp.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file.zcp.P1.E2)) {
  lmm.zcp.P1.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere + 
                          (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                             Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                             Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi + 
                             Type_Cate_Dura_Hemi
                           || SubjCode) +
                          (1 + Type_C + Dura_C + Hemi_C + 
                             Type_Dura + Type_Hemi + Dura_Hemi +
                             Type_Dura_Hemi 
                           || Stimuli),
                        data = df.erp.P1.E2,
                        verbose = TRUE,
                        control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                              optCtrl = list(maxfun = 1e7)))
} else {
  load(file.zcp.P1.E2)
}

print(summary(lmm.zcp.P1.E2), corr = FALSE)

```


#### The reduced model
```{r PCA analysis for zcp lmm for E2 P1}
summary(rePCA(lmm.zcp.P1.E2))
```


```{r }

file.rdc.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file.rdc.P1.E2)) {
  # lmm.rdc.P1.E2.step <- step(lmm.rdc.P1.E2, reduce.fixed = FALSE)
  
  lmm.rdc.P1.E2 <- update(lmm.zcp.P1.E2,
                          formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                               Type_Cate + Type_Dura + Cate_Dura + Dura_Hemi
                             || SubjCode) +
                            (1 + Type_C + Dura_C +
                               Type_Dura 
                             || Stimuli))
  
} else {
  load(file.rdc.P1.E2)
}

print(summary(lmm.rdc.P1.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.P1.E2, lmm.zcp.P1.E2, refit = FALSE)
```

#### The extended model
```{r }

file.etd.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_etd.RData")

# fit the etd model
if (!file.exists(file.etd.P1.E2)) {
  
  lmm.etd.P1.E2 <- update(lmm.rdc.P1.E2,
                          formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                               Type_Cate + Type_Dura + Cate_Dura + Dura_Hemi
                             | SubjCode) +
                            (1 + Type_C + Dura_C + 
                               Type_Dura
                             | Stimuli))
  
  lmm.etd.P1.E2.2 <- re_fit(lmm.etd.P1.E2)
  
} else {
  load(file.etd.P1.E2)
}

print(summary(lmm.etd.P1.E2.2), corr = FALSE)

```

```{r}
anova(lmm.etd.P1.E2.2, lmm.rdc.P1.E2, refit = FALSE)
```

The reduced model (`lmm.rdc.P1.E2`) explained the data better than the extended model (`lmm.rdc.P1.E2.2`).

#### The optimal model
```{r }

lmm.opt.P1.E205 <- lmm.rdc.P1.E2

# print(summary(lmm.opt.P1.E2), corr = FALSE)

summary(lmm.opt.P1.E205)

# confint(lmm.opt.P1.E205, method="Wald")
```

#### Diagnostic plots
```{r qqplot for lmm.opt.P1.E205}
# qqplot
qqplot_lmer(lmm.opt.P1.E205)
```

#### Estimated marginal means
```{r}
emm.P1.E205 <- emmeans(lmm.opt.P1.E205, ~ Type + Duration + Hemisphere + Category )

emm.P1.E205 %>% 
  as.data.frame() %>% 
  select(Type, Category, Duration, Hemisphere, everything())

```


#### Plots
```{r}
# emmip(emm.P1.E205, Category ~ Duration | Type + Hemisphere, CIs = TRUE)

```


```{r p1.all.LinePlot}

hemiLabel <- c("left", "right")
names(hemiLabel) <- c("Left", "Right")

p1.all.LinePlot = {
  ggplot(data = data.frame(emm.P1.E205), aes(y = emmean, x = Duration, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(Type ~ Hemisphere, # switch = "x", 
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration (ms)", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme 
}

# p1.all.LinePlot.slide <- {
#   p1.all.LinePlot + 
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('P1_all.png', p1.all.LinePlot.slide, width = 7, height = 4)

p1.all.LinePlot
```


#### Contrasts
```{r P1 amplitudes for all}
contra.all.P1.gen <- contrast(emmeans(lmm.opt.P1.E205, ~ Duration | Hemisphere + Category + Type), 
                              "pairwise", adjust = "Bonferroni")

contra.all.P1.gen[1:2]

confint(contra.all.P1.gen[1:2])

```


```{r}
contra.all.P1.spec <- contrast(emmeans(lmm.opt.P1.E205, ~ Category + Duration | Hemisphere + Type), 
                               interaction = "pairwise", adjust = "Bonferroni")

contra.all.P1.spec[1:2]
confint(contra.all.P1.spec[1:2])

```

```{r}
contra.all.P1.gen[1:8]

confint(contra.all.P1.gen[1:8])
```


```{r}
contra.all.P1.spec
# confint(contra.all.P1.spec[1:4])
```

```{r eval=FALSE, include=FALSE}
emm.dt.all <- emmeans(lmm.opt.P1.E2, ~ Duration + Type)
emm.dt.all

contra.all.P1 <- contrast(emm.dt.all, "pairwise", simple = "each", combine = TRUE)

contra.all.P1
confint(contra.all.P1)
```


### Ampitudes of the N170
```{r erp df for the N170 E2}
# only keep the data for amplitudes of the N170 (all erps)
df.erp.N170.E2 <- {
  df.erp.E2.all %>% 
    filter(Component == "N170") 
}

if (saveCSV) {
  output.erp.N170.E2 <- file.path(folder_nesi, "E205_erp_N170.RData")
  save(df.erp.N170.E2, file = output.erp.N170.E2)
}

# the structure of this dataset
head(df.erp.N170.E2, 10)
```


#### The maximal model
```{r maximal lmm for E2 N170}
file.max.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_max.RData")

# fit the maximal model
if (!file.exists(file.max.N170.E2)) {
  lmm.max.N170.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere +
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +
                               Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                               Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi +
                               Type_Cate_Dura_Hemi
                             | SubjCode) +
                            (1 + Type_C + Dura_C + Hemi_C +
                               Type_Dura + Type_Hemi + Dura_Hemi +
                               Type_Dura_Hemi
                             | Stimuli),
                          data = df.erp.N170.E2,
                          verbose = TRUE,
                          control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                optCtrl = list(maxfun = 1e7)))
} else {
  load(file.max.N170.E2)
}

print(summary(lmm.max.N170.E2), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r zcp lmm for E2 N170}

file.zcp.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file.zcp.N170.E2)) {
  lmm.zcp.N170.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere + 
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                               Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                               Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi + 
                               Type_Cate_Dura_Hemi 
                             || SubjCode) +
                            (1 + Type_C + Dura_C + Hemi_C + 
                               Type_Dura + Type_Hemi + Dura_Hemi +
                               Type_Dura_Hemi 
                             || Stimuli),
                          data = df.erp.N170.E2,
                          verbose = TRUE,
                          control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                optCtrl = list(maxfun = 1e7)))
  
} else {
  load(file.zcp.N170.E2)
}


print(summary(lmm.zcp.N170.E2), corr = FALSE)

```


#### The reduced model
```{r PCA analysis for zcp lmm for E2 N170}

summary(rePCA(lmm.zcp.N170.E2))
```


```{r}

file.rdc.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file.rdc.N170.E2)) {
  # lmm.rdc.N170.E2.step <- step(lmm.rdc.N170.E2, reduce.fixed = FALSE)
  
  lmm.rdc.N170.E2 <- update(lmm.zcp.N170.E2,
                            formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                              (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                                 Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                                 Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi
                               || SubjCode) +
                              (1 + Type_C + Dura_C + 
                                 Type_Dura
                               || Stimuli))
  
} else {
  load(file.rdc.N170.E2)
}

print(summary(lmm.rdc.N170.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.N170.E2, lmm.zcp.N170.E2, refit = FALSE)
```

#### The extended model
```{r }

file.etd.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd.RData")

# fit the etd model
if (!file.exists(file.etd.N170.E2)) {
  
  lmm.etd.N170.E2 <- update(lmm.rdc.N170.E2,
                            formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                              (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                                 Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                                 Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi
                               | SubjCode) +
                              (1 + Type_C + Dura_C + 
                                 Type_Dura
                               | Stimuli))
  
} else {
  load(file.etd.N170.E2)
}

print(summary(lmm.etd.N170.E2), corr = FALSE)

```

```{r}
summary(rePCA(lmm.etd.N170.E2))
```

```{r }

file.etd1.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file.etd1.N170.E2)) {
  
  lmm.etd1.N170.E2 <- update(lmm.etd.N170.E2,
                             formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                               (1 + Type_C + Dura_C + Hemi_C +  
                                  Type_Cate + Type_Dura + Type_Hemi + Dura_Hemi +
                                  Type_Cate_Dura + Type_Cate_Hemi
                                | SubjCode) +
                               (1 + Type_C + Dura_C + 
                                  Type_Dura
                                | Stimuli))
  
} else {
  load(file.etd1.N170.E2)
}

print(summary(lmm.etd1.N170.E2), corr = FALSE)

```


```{r}
summary(rePCA(lmm.etd1.N170.E2))
```


```{r }

file.etd2.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file.etd2.N170.E2)) {
  
  lmm.etd2.N170.E2 <- update(lmm.etd1.N170.E2,
                             formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                               (1 + Type_C + Dura_C + Hemi_C +  
                                  Type_Cate + Type_Dura + Dura_Hemi +
                                  Type_Cate_Dura + Type_Cate_Hemi
                                | SubjCode) +
                               (1 + Type_C + Dura_C + 
                                  Type_Dura
                                | Stimuli))
  
} else {
  load(file.etd2.N170.E2)
}

print(summary(lmm.etd2.N170.E2), corr = FALSE)

```

```{r}
summary(rePCA(lmm.etd2.N170.E2))
```


```{r }

file.etd3.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file.etd3.N170.E2)) {
  
  lmm.etd3.N170.E2 <- update(lmm.etd2.N170.E2,
                             formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                               (1 + Dura_C + Hemi_C +  
                                  Type_Cate + Type_Dura + Dura_Hemi +
                                  Type_Cate_Dura + Type_Cate_Hemi
                                | SubjCode) +
                               (0 + Type_C + Dura_C + 
                                  Type_Dura
                                | Stimuli))
  
} else {
  load(file.etd3.N170.E2)
}

print(summary(lmm.etd3.N170.E2), corr = FALSE)

```


```{r}
anova(lmm.etd3.N170.E2, lmm.rdc.N170.E2, refit = FALSE)
```

#### The optimal model
```{r }

lmm.opt.N170.E205 <- lmm.rdc.N170.E2

print(summary(lmm.opt.N170.E205), corr = FALSE)

```


#### Diagnostic plots
```{r qqplot for lmm.opt.N170.E2}
# qqplot
qqplot_lmer(lmm.opt.N170.E205)
```

#### Estimated marginal means
```{r}
emm.N170.E205 <- emmeans(lmm.opt.N170.E205,  ~ Duration + Category + Hemisphere + Type)

emm.N170.E205 %>% 
  as.data.frame() %>% 
  select(Type, Category, Duration, Hemisphere, everything())

```


#### Plots
```{r}
# emmip(emm.N170.E205, Category ~ Duration | Type + Hemisphere, CIs = TRUE) + 
#   scale_y_continuous(trans = "reverse")

```

```{r n170.all.LinePlot}

n170.all.LinePlot = {
  ggplot(data = data.frame(emm.N170.E205), aes(y = emmean, x = Duration, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(Type ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration (ms)", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme 
}

# n170.all.LinePlot.slide <- {
#   n170.all.LinePlot + 
#     scale_y_reverse(limits = c(0.8, -4.8), breaks = seq(0, -4, -1)) +  # set the limit for y axis
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('N170_all.png', n170.all.LinePlot.slide, width = 7, height = 4)

n170.all.LinePlot
```
#### Contrasts
```{r}
contra.all.N170 <- contrast(emm.N170.E205, "pairwise", simple = "each", combine = TRUE, adjust = "none")

contra.all.N170
confint(contra.all.N170)
```

```{r N170 amplitudes for all}
contra.all.N170.gen <- contrast(emmeans(lmm.opt.N170.E205, ~ Duration | Hemisphere + Category + Type), 
                                "pairwise")

contra.all.N170.gen[1:2]

confint(contra.all.N170.gen[1:2])


contra.all.N170.gen.hemi <- contrast(emmeans(lmm.opt.N170.E205, ~ Duration + Hemisphere |Category + Type), 
                                     interaction = "pairwise")

contra.all.N170.gen.hemi[1]

confint(contra.all.N170.gen.hemi[1])
```




```{r}
contra.all.N170.spec <- contrast(emmeans(lmm.opt.N170.E205, ~ Category + Duration | Hemisphere + Type), 
                                 interaction = "pairwise", adjust = "Bonferroni")

contra.all.N170.spec[c(1,2)]
confint(contra.all.N170.spec[c(1,2)])

contra.all.N170.spec.hemi <- contrast(emmeans(lmm.opt.N170.E205, ~ Category + Duration + Hemisphere | Type), 
                                      interaction = "pairwise")

contra.all.N170.spec.hemi
confint(contra.all.N170.spec[c(1,2)])
```



```{r}

contra.all.N170.gen[1:8]

confint(contra.all.N170.gen[1:8])


contra.all.N170.gen.hemi[1:4]

confint(contra.all.N170.gen.hemi[1:4])
```


```{r}

contra.all.N170.spec

# contra.all.N170.spec.hemi

```


## Linear mixed model with subjective confidence

### Converting response to subjective confidence
```{r}
df.erp.SC.E2 <- {
  df.erp.E2 %>% 
    filter(Type == "intact") %>%  # only keep the intact trials
    mutate(Confidence = if_else(Response %in% c("11", "55"), "high", 
                                if_else(Response %in% c("12", "54"), "low",
                                        if_else(substring(Response, 2) == "3", "guess", "NA"))),
           DuraConf = paste(Duration, Confidence, sep = "_")) %>% 
    filter(Confidence != "NA",
           !(DuraConf %in% c("200_guess", "200_low"))) %>% 
    mutate(Confidence = as.factor(Confidence),
           DuraConf = as.factor(DuraConf))
}
```


### Set the successive difference coding
```{r set the successive difference coding for ERP data E2 SC}
# successive difference coding
df.erp.SC.E2 <- sdif_coding_E205_erp(df.erp.SC.E2)
```

### Amplitudes of the P1
```{r erp df for the P1 E2 SC}
# only keep the data for amplitudes of the P1 (correct and incorrect erps)
df.erp.P1.SC.E2 <- {
  df.erp.SC.E2 %>% 
    filter(Component == "P1") 
}

if (saveCSV) {
  output.erp.P1.SC.E2 <- file.path(folder_nesi, "E205_erp_P1_SC.RData")
  save(df.erp.P1.SC.E2, file = output.erp.P1.SC.E2)
}

# the structure of this dataset
head(df.erp.P1.SC.E2, 10)
```


#### The maximal model
```{r maximal lmm for P1 E2 SC}

lmm.max.P1.SC.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraConf +
                           (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                           (1 + Hemi_C | Stimuli),
                         data = df.erp.P1.SC.E2,
                         verbose = TRUE,
                         control = lmerControl(optimizer = "bobyqa"))  # nloptwrap Nelder_Mead

print(summary(lmm.max.P1.SC.E2), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r zcp lmm for P1 E2 SC}

lmm.zcp.P1.SC.E2 <- update(lmm.max.P1.SC.E2,
                           formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                             (1 + Hemi_C || Stimuli))

print(summary(lmm.zcp.P1.SC.E2), corr = FALSE)

```


#### The reduced model
```{r PCA analysis for zcp lmm for E2 P1 SC}
summary(rePCA(lmm.zcp.P1.SC.E2))
```


```{r }

lmm.rdc.P1.SC.E2 <- update(lmm.zcp.P1.SC.E2,
                           formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C || SubjCode) +
                             (1 | Stimuli))


print(summary(lmm.rdc.P1.SC.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.P1.SC.E2, lmm.zcp.P1.SC.E2, refit = FALSE)
```


#### The extended model
```{r }


lmm.etd.P1.SC.E2 <- update(lmm.rdc.P1.SC.E2,
                           formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C | SubjCode) +
                             (1 | Stimuli))


print(summary(lmm.etd.P1.SC.E2), corr = FALSE)

```


```{r}
anova(lmm.rdc.P1.SC.E2, lmm.etd.P1.SC.E2, refit = FALSE)
```

#### The optimal model
```{r }

lmm.opt.P1.SC.E205 <- lmm.etd.P1.SC.E2

# print(summary(lmm.opt.P1.SC.E2), corr = FALSE)
summary(lmm.opt.P1.SC.E205)

confint(lmm.opt.P1.SC.E205, method = "Wald")

anova(lmm.opt.P1.SC.E205)

```


#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.P1.SC.E205)
```


#### Estimated marginal means
```{r}
emm.P1.SC.E205 <- emmeans(lmm.opt.P1.SC.E205, ~ DuraConf + Category | Hemisphere)

emm.P1.SC.E205
```


#### Plots
```{r}
# emmip(emm.P1.SC.E205, Category ~ DuraConf | Hemisphere, CIs = TRUE)
```

```{r p1.conf.LinePlot}

duraconf.labels = c("17ms\nguess", "17ms\nlow", "17ms\nhigh", "200ms\nhigh")

p1.conf.LinePlot = {
  ggplot(data = data.frame(emm.P1.SC.E205), aes(y = emmean, x = DuraConf, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    scale_x_discrete(labels = duraconf.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# p1.conf.LinePlot.slide <- {
#   p1.conf.LinePlot + 
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('P1_conf.png', p1.conf.LinePlot.slide, width = 8.5, height = 4)

p1.conf.LinePlot
```


#### Contrast
```{r}
# contra.SC.P1 <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ DuraConf + Category), "pairwise", simple = "each", combine = TRUE)
#   
# contra.SC.P1
# confint(contra.SC.P1)
```

```{r P1 amplitudes for SC}
contra.SC.P1.gen <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ DuraConf | Hemisphere + Category), # 
                             "pairwise", adjust = "Bonferroni")

contra.SC.P1.gen[1:6]

confint(contra.SC.P1.gen[1:6])

contra.SC.P1.gen[7:12]

confint(contra.SC.P1.gen[7:12])

# differences between hemispheres
contra.SC.P1.gen.hemi <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ DuraConf + Hemisphere | Category), # 
                                  interaction = "pairwise", adjust = "Bonferroni")
contra.SC.P1.gen.hemi
```

```{r}
contra.SC.P1.gen.nohemi <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ DuraConf | Category), # 
                                    "pairwise", adjust = "Bonferroni")

contra.SC.P1.gen.nohemi[1:6]
confint(contra.SC.P1.gen.nohemi[1:6])
```


```{r}
contra.SC.P1.spec <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ Category + DuraConf | Hemisphere), # 
                              interaction = "pairwise", adjust = "Bonferroni")

contra.SC.P1.spec
confint(contra.SC.P1.spec)


contra.SC.P1.spec.hemi <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ Category + DuraConf + Hemisphere ), # 
                                   interaction = "pairwise", adjust = "Bonferroni")

contra.SC.P1.spec.hemi
```

```{r eval=FALSE, include=FALSE}
# contra.SC.P1.dc <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ DuraConf), "pairwise", adjust = "Bonferroni")
#   
# contra.SC.P1.dc
# 
# confint(contra.SC.P1.dc)
```


### Ampitudes of the N170
```{r erp df for the N170 E2 SC}
# only keep the data for amplitudes of the N170 (all erps)
df.erp.N170.SC.E2 <- {
  df.erp.SC.E2 %>% 
    filter(Component == "N170") 
}

if (saveCSV) {
  output.erp.N170.SC.E2 <- file.path(folder_nesi, "E205_erp_N170_SC.RData")
  save(df.erp.N170.SC.E2, file = output.erp.N170.SC.E2)
}

# the structure of this dataset
head(df.erp.N170.SC.E2, 10)
```


#### The maximal model
```{r maximal lmm for E2 N170 SC}

lmm.max.N170.SC.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                             (1 + Hemi_C | Stimuli),
                           data = df.erp.N170.SC.E2,
                           verbose = TRUE,
                           control = lmerControl(optimizer = "bobyqa"))  # nloptwrap Nelder_Mead

print(summary(lmm.max.N170.SC.E2), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r zcp lmm for E2 N170 SC}


lmm.zcp.N170.SC.E2 <- update(lmm.max.N170.SC.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                               (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                               (1 + Hemi_C || Stimuli))


print(summary(lmm.zcp.N170.SC.E2), corr = FALSE)

```

```{r compare max and zcp E2 N170 SC}
anova(lmm.max.N170.SC.E2, lmm.zcp.N170.SC.E2, refit = FALSE)
```

#### The reduced model
```{r PCA analysis for zcp lmm for E2 N170 SC}
summary(rePCA(lmm.zcp.N170.SC.E2))
```


```{r}

lmm.rdc.N170.SC.E2 <- update(lmm.zcp.N170.SC.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                               (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                               (1 | Stimuli))


print(summary(lmm.rdc.N170.SC.E2), corr = FALSE)

```


```{r}
anova(lmm.rdc.N170.SC.E2, lmm.zcp.N170.SC.E2, refit = FALSE)
```

#### The extended model
```{r}

lmm.etd.N170.SC.E2 <- update(lmm.rdc.N170.SC.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                               (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                               (1 | Stimuli))


print(summary(lmm.rdc.N170.SC.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.N170.SC.E2, lmm.etd.N170.SC.E2, refit = FALSE)
```

#### The optimal model
```{r }

lmm.opt.N170.SC.E205 <- lmm.etd.N170.SC.E2

print(summary(lmm.opt.N170.SC.E205), corr = FALSE)

anova(lmm.opt.N170.SC.E205)
```

#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.N170.SC.E205)
```

#### Estimated marginal means
```{r}
emm.N170.SC.E205 <- emmeans(lmm.opt.N170.SC.E205, ~ Category + DuraConf | Hemisphere)

emm.N170.SC.E205
```


#### Plots
```{r}
# emmip(emm.N170.SC.E205, Category ~ DuraConf | Hemisphere, CIs = TRUE) + 
#   scale_y_continuous(trans = "reverse")
```

```{r N170.conf.LinePlot}

duraconf.labels = c("17ms\nguess", "17ms\nlow", "17ms\nhigh", "200ms\nhigh")

n170.conf.LinePlot = {
  ggplot(data = data.frame(emm.N170.SC.E205), aes(y = emmean, x = DuraConf, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    scale_x_discrete(labels = duraconf.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# n170.conf.LinePlot.slide <- {
#   n170.conf.LinePlot + 
#     scale_y_reverse(limits = c(0.8, -4.8), breaks = seq(0, -4, -1)) +  # set the limit for y axis
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('N170_confi.png', n170.conf.LinePlot.slide, width = 8.5, height = 4)

n170.conf.LinePlot
```

#### Contrast
```{r}
# contra.N170.resp <- contrast(emm.N170.SC.E205, "pairwise", simple = "each", combine = FALSE, adjust = "Bonferroni")
# 
# contra.N170.resp
# confint(contra.N170.resp)
```


```{r N170 amplitudes for SC}
contra.SC.N170.gen <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ DuraConf | Hemisphere + Category), # 
                               "pairwise", adjust = "Bonferroni")

contra.SC.N170.gen[1:6]

confint(contra.SC.N170.gen[1:6])

contra.SC.N170.gen[7:12]

confint(contra.SC.N170.gen[7:12])

contra.SC.N170.gen.hemi <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ DuraConf + Hemisphere | Category), # 
                                    interaction = "pairwise", adjust = "Bonferroni")

contra.SC.N170.gen.hemi[1:6]
confint(contra.SC.N170.gen.hemi[1:6])

```


```{r}
contra.SC.N170.spec <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ Category + DuraConf | Hemisphere), # 
                                interaction = "pairwise", adjust = "Bonferroni")

contra.SC.N170.spec[1:6]
confint(contra.SC.N170.spec[1:6])

contra.SC.N170.spec[7:12]
confint(contra.SC.N170.spec[7:12])

contra.SC.N170.spec.hemi <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ Category + DuraConf + Hemisphere), # 
                                     interaction = "pairwise", adjust = "Bonferroni")

contra.SC.N170.spec.hemi

```



```{r eval=FALSE, include=FALSE}

contra.N170.resp.nohemi.dura <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ DuraConf | Category), 
                                         "pairwise", adjust = "Bonferroni")

contra.N170.resp.nohemi.dura
confint(contra.N170.resp.nohemi.dura)


contra.N170.resp.nohemi.cate <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ Category | DuraConf),
                                         "pairwise", adjust = "Bonferroni")

contra.N170.resp.nohemi.cate
confint(contra.N170.resp.nohemi.cate)
```


```{r eval=FALSE, include=FALSE}
# contra.N170.resp.nohemi.inter <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ Category + DuraConf), 
#                                     interaction = "pairwise", adjust = "Bonferroni")
# 
# contra.N170.resp.nohemi.inter
# confint(contra.N170.resp.nohemi.inter)
```




```{r eval=FALSE, include=FALSE}

# contra.N170.resp.nocate.dura <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ DuraConf | Hemisphere), 
#                                     "pairwise", adjust = "Bonferroni")
# 
# contra.N170.resp.nocate.dura
# confint(contra.N170.resp.nocate.dura)
# 
# contra.N170.resp.nocate.hemi <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ Hemisphere | DuraConf), 
#                                     "pairwise", adjust = "Bonferroni")
# 
# contra.N170.resp.nocate.hemi
# confint(contra.N170.resp.nocate.hemi)
```




## Linear mixed model with high subjective confidences 

```{r}
tmpBlock.count <- {
  clean_beha_205 %>% 
    filter(Type == "intact") %>% 
    group_by(SubjCode, Category, Duration, blockID) %>% 
    summarize(Count_sum = n())
}

avg.resp.long.E205.Block <- {
  clean_beha_205 %>% 
    filter(Type == "intact") %>% 
    group_by(SubjCode, Category, Duration, blockID, Resp) %>% 
    summarize(Count = n()) %>% 
    
    right_join(tmpBlock.count, by = c("SubjCode", "blockID", "Category", "Duration")) %>% 
    mutate(RespRate = Count / Count_sum) %>% 
    ungroup()
}

# descriptive statistics of accuracy for plotting
desc.resp.E205.Block <- {
  avg.resp.long.E205.Block %>%
    group_by(blockID, Category, Duration, Resp) %>%
    summarize(Mean = mean(RespRate)
              , N = n()
              , SD = if_else(N > 1, sd(RespRate), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI = SE * qt(0.975,N)
              , Median = median(RespRate)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>% 
    ungroup() %>% 
    add_row(blockID = 2, Category = "house", Duration = 200, Resp = 2, Mean = 0, N = 0, SD = 0, SE = 0, SE.lo = 0,
            SE.hi = 0, CI = 0, Median = 0, Lower = 0, Upper = 0)
}

avg.resp.wide.E205.Block <- {
  avg.resp.long.E205.Block %>% 
    mutate(Conditions = paste(blockID, Category, Duration, Resp, sep = "_")) %>% 
    select(SubjCode, Conditions, RespRate) %>% 
    spread(Conditions, RespRate)
}


```

```{r}
block.high <- {
  avg.resp.long.E205.Block %>% 
    filter(Category == "face", Duration == 17, Resp == 1, SubjCode != "P513") 
}

t.test(filter(block.high, blockID == 1)$RespRate, filter(block.high, blockID == 2)$RespRate, paired = T)


```


```{r rainclound plot of the RT data E205 block, warning = FALSE}
knitr::kable(desc.resp.E205.Block, digits = 4)

rt.RainPlot.E205.Block <- {
  ggplot(data = avg.resp.long.E205.Block, aes(y = RespRate, x = as.factor(Resp), fill = Category)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RespRate, color = Category), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RespRate), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.resp.E205.Block, aes(y = Mean, x = Resp, color = Category), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.resp.E205.Block, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(Duration ~ blockID) +
    
    # facet_grid(. ~ Type, switch = "x") +  # create two panels to show data
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") + # palette = "RdBu"
    # scale_fill_brewer(palette = "Set1") + # palette = "RdBu"
    labs(title = "Reaction times for E205", x = "Stimulus Type", y = "Reaction times (ms)", fill = "Duration(ms)", color = "Duration(ms)") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot for reaction times block}
rt.RainPlot.E205.Block
```


```{r}

bloc.labels <- c("1st Half", "2nd Half")
names(bloc.labels) <- c(1, 2)

acc.ColuPlot.E205.Block <- {
  ggplot(data = desc.resp.E205.Block, aes(y = Mean, x = Resp, fill = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Duration ~ blockID,
               labeller = labeller(Duration = dura.labels,
                                   blockID = bloc.labels)) +
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "", x = "Responses", y = "Percentage", fill = "Category") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    erp_theme
}

acc.ColuPlot.E205.Block

```


```{r}
df.ratio.E205.Block <- {
  clean_beha_205 %>%
    filter(Type == "intact") %>% 
    mutate(isFace = if_else(Category == "face", 1, 0)) %>% 
    group_by(SubjCode, blockID, Duration, Resp) %>% 
    summarize(ratio = mean(isFace), Count = n())
}

desc.ratio.E205.Block <- {
  df.ratio.E205.Block %>%
    group_by(blockID, Duration, Resp) %>%
    summarize(Mean = mean(ratio)
              , N = n()
              , SD = if_else(N > 1, sd(ratio), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI = SE * qt(0.975,N)
              , Median = median(ratio)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>% 
    ungroup()
}

```



```{r}

ratio.ColuPlot.E205.Block <- {
  ggplot(data = desc.ratio.E205.Block, aes(y = Mean, x = Resp)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Duration ~ blockID,
               labeller = labeller(Duration = dura.labels,
                                   blockID = bloc.labels)) +
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "", x = "Responses", y = "Percentage") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    plot_theme
}

ratio.ColuPlot.E205.Block

```


```{r}
df.erp.high.E2 <- {
  df.erp.SC.E2 %>% 
    filter(Confidence == "high") %>% 
    mutate(DuraBlock = paste(Duration, Block_ST_table, sep = "_")) %>% 
    sdif_coding_E205_erp_conf()
}

```


### Amplitudes of the P1
```{r erp df for the P1 E2 high}
# only keep the data for amplitudes of the P1 (correct and incorrect erps)
df.erp.P1.high.E2 <- {
  df.erp.high.E2 %>% 
    filter(Component == "P1")
}

if (saveCSV) {
  output.erp.P1.high.E2 <- file.path(folder_nesi, "E205_erp_P1_high.RData")
  save(df.erp.P1.high.E2, file = output.erp.P1.high.E2)
}

# the structure of this dataset
head(df.erp.P1.high.E2, 10)
```


#### The maximal model
```{r maximal lmm for P1 E2 high}

lmm.max.P1.high.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraBlock +
                             (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                             (1 + Hemi_C | Stimuli),
                           data = df.erp.P1.high.E2,
                           verbose = TRUE,
                           control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                 optCtrl = list(maxfun = 1e5)))

print(summary(lmm.max.P1.high.E2), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r zcp lmm for P1 E2 high}

lmm.zcp.P1.high.E2 <- update(lmm.max.P1.high.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                               (1 + Hemi_C || Stimuli))


print(summary(lmm.zcp.P1.high.E2), corr = FALSE)

```


#### The reduced model
```{r}
summary(rePCA(lmm.zcp.P1.high.E2))
```


```{r}
lmm.rdc.P1.high.E2 <- update(lmm.zcp.P1.high.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C || SubjCode) +
                               (1 | Stimuli))

print(summary(lmm.rdc.P1.high.E2), corr = FALSE)
```

```{r}
anova(lmm.rdc.P1.high.E2, lmm.zcp.P1.high.E2, refit = FALSE)
```

#### The extended model

```{r}
lmm.etd.P1.high.E2 <- update(lmm.rdc.P1.high.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C | SubjCode) +
                               (1 | Stimuli))

print(summary(lmm.etd.P1.high.E2), corr = FALSE)
```

```{r}
anova(lmm.etd.P1.high.E2, lmm.rdc.P1.high.E2, refit = FALSE)
```

#### The optimal model

```{r}
lmm.opt.P1.high.E205 <- lmm.etd.P1.high.E2

summary(lmm.opt.P1.high.E205)

anova(lmm.opt.P1.high.E205)
```

#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.P1.high.E205)
```



#### Estimated marginal means

```{r}
emm.P1.high.E205 <- emmeans(lmm.opt.P1.high.E205, ~ DuraBlock | Category + Hemisphere)

emm.P1.high.E205
```

#### Plots
```{r}
# emmip(emm.P1.high.E205, Category ~ DuraBlock | Hemisphere, CIs = TRUE)
```


```{r p1.high.LinePlot}

durablock.labels = c("17ms\nhalf 1", "17ms\nhalf 2", "200ms\nhalf 2")

p1.high.LinePlot = {
  ggplot(data = data.frame(emm.P1.high.E205), aes(y = emmean, x = DuraBlock, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    scale_x_discrete(labels = durablock.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# p1.high.LinePlot.slide <- {
#   p1.high.LinePlot + 
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('P1_high.png', p1.high.LinePlot.slide, width = 7.5, height = 4)

p1.high.LinePlot
```


#### Contrast
```{r}
# contrast(emmeans(lmm.opt.P1.high.E205, ~ DuraBlock | Category + Hemisphere), "pairwise", simple = "each", combine = TRUE)
```

```{r P1 amplitudes for high}
contra.high.P1.gen <- contrast(emmeans(lmm.opt.P1.high.E205, ~ DuraBlock | Hemisphere + Category), # 
                               "pairwise", adjust = "none")

contra.high.P1.gen[1:3]

confint(contra.high.P1.gen[1:3])

contra.high.P1.gen[4:6]

confint(contra.high.P1.gen[4:6])

contra.high.P1.gen.hemi <- contrast(emmeans(lmm.opt.P1.high.E205, ~ DuraBlock + Hemisphere | Category), # 
                                    interaction = "pairwise", adjust = "none")
contra.high.P1.gen.hemi

```


```{r}
contra.high.P1.spec <- contrast(emmeans(lmm.opt.P1.high.E205, ~ Category + DuraBlock | Hemisphere), # 
                                interaction = "pairwise", adjust = "Bonferroni")

contra.high.P1.spec
confint(contra.high.P1.spec)

contra.high.P1.spec.hemi <- contrast(emmeans(lmm.opt.P1.high.E205, ~ Category + DuraBlock + Hemisphere), # 
                                     interaction = "pairwise", adjust = "Bonferroni")

contra.high.P1.spec.hemi

```


### Amplitudes of the N170
```{r erp df for the N170 E2 high}
# only keep the data for amplitudes of the N170 (correct and incorrect erps)
df.erp.N170.high.E2 <- {
  df.erp.high.E2 %>% 
    filter(Component == "N170")
}

if (saveCSV) {
  output.erp.N170.high.E2 <- file.path(folder_nesi, "E205_erp_N170_high.RData")
  save(df.erp.N170.high.E2, file = output.erp.N170.high.E2)
}

# the structure of this dataset
head(df.erp.N170.high.E2, 10)
```


#### The maximal model
```{r maximal lmm for N170 E2 high}

lmm.max.N170.high.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                               (1 + Hemi_C | Stimuli),
                             data = df.erp.N170.high.E2,
                             verbose = TRUE,
                             control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                   optCtrl = list(maxfun = 1e5)))

print(summary(lmm.max.N170.high.E2), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r zcp lmm for N170 E2 high}

lmm.zcp.N170.high.E2 <- update(lmm.max.N170.high.E2,
                               formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                                 (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                                 (1 + Hemi_C || Stimuli))

print(summary(lmm.zcp.N170.high.E2), corr = FALSE)

```


#### The reduced model
```{r}
summary(rePCA(lmm.zcp.N170.high.E2))
```

```{r}
lmm.rdc.N170.high.E2 <- update(lmm.zcp.N170.high.E2,
                               formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                                 (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                                 (1 | Stimuli))

print(summary(lmm.rdc.N170.high.E2), corr = FALSE)
```

```{r}
anova(lmm.rdc.N170.high.E2, lmm.zcp.N170.high.E2, refit = FALSE)
```

#### The extended model
```{r}
lmm.etd.N170.high.E2 <- update(lmm.rdc.N170.high.E2,
                               formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                                 (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                                 (1 | Stimuli))

print(summary(lmm.etd.N170.high.E2), corr = FALSE)
```

```{r}
anova(lmm.etd.N170.high.E2, lmm.rdc.N170.high.E2, refit = FALSE)
```

#### The optimal model
```{r}
lmm.opt.N170.high.E205 <- lmm.etd.N170.high.E2

summary(lmm.opt.N170.high.E205)

anova(lmm.opt.N170.high.E205)
```

#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.N170.high.E205)
```


#### Estimated marginal means
```{r}
emm.N170.high.E205 <- emmeans(lmm.opt.N170.high.E205, ~ DuraBlock | Category + Hemisphere)

emm.N170.high.E205
```


#### Plots
```{r}
# emmip(emm.N170.high.E205, Category ~ DuraBlock | Hemisphere, CIs = TRUE) +
#   scale_y_continuous(trans = "reverse")

```


```{r n170.high.LinePlot}

n170.high.LinePlot = {
  ggplot(data = data.frame(emm.N170.high.E205), aes(y = emmean, x = DuraBlock, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    scale_x_discrete(labels = durablock.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# n170.high.LinePlot.slide <- {
#   n170.high.LinePlot + 
#     scale_y_reverse(limits = c(0.8, -4.8), breaks = seq(0, -4, -1)) +  # set the limit for y axis
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('N170_high.png', n170.high.LinePlot.slide, width = 7.5, height = 4)

n170.high.LinePlot
```


#### Contrast
```{r}
# contra.high.N170 <- contrast(emmeans(lmm.opt.N170.high.E205, ~ Category + DuraBlock), "pairwise", simple = "each")
# 
# contra.high.N170
# 
# confint(contra.high.N170)
```

```{r N170 amplitudes for high}
contra.high.N170.gen <- contrast(emmeans(lmm.opt.N170.high.E205, ~ DuraBlock | Hemisphere + Category), # 
                                 "pairwise", adjust = "Bonferroni", infer = TRUE)

contra.high.N170.gen[1:3]

contra.high.N170.gen[4:6]

contra.high.N170.gen.hemi <- contrast(emmeans(lmm.opt.N170.high.E205, ~ DuraBlock + Hemisphere | Category), # 
                                      interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra.high.N170.gen.hemi
```

```{r}
contra.high.N170.spec <- contrast(emmeans(lmm.opt.N170.high.E205, ~ Category + DuraBlock | Hemisphere), # 
                                  interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra.high.N170.spec[1:3]

contra.high.N170.spec[4:6]

contra.high.N170.spec.hemi <- contrast(emmeans(lmm.opt.N170.high.E205, ~ Category + DuraBlock + Hemisphere), # 
                                       interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra.high.N170.spec.hemi
```


```{r eval=FALSE, include=FALSE}
# contra.high.N170.spec <- contrast(emmeans(lmm.opt.N170.high.E205, ~ Category + DuraBlock), 
#                                   interaction = "pairwise", adjust = "Bonferroni")
# 
# contra.high.N170.spec
# confint(contra.high.N170.spec)
```


### Bayesian mixed modeling of the N170 (high subjective confidence)
Since the differences being non-significant in the linear mixed modeling is not informative whether N170 amplitudes of faces presented for 17ms and 200ms were the same when they are perceived with high subjective perception. Bayesian mixed modeling is used to answer this question.

```{r message=FALSE}
library(rstan)
library(brms)
library(tidybayes)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

```


```{r set priors}
# list all the parameters to be set priors
get_prior(MeanAmp ~ Category * Hemisphere * DuraBlock +
            (1 + Category * Hemisphere * DuraBlock | SubjCode) +
            (1 + Hemisphere * DuraBlock | Stimuli),
          data = df.erp.N170.high.E2)

# set priors
prior.N170.high <- c(
  prior(normal(-3, 4), class = Intercept),
  prior(normal(0, 1.5), class = b),
  prior(normal(0, 5), class = sigma),
  prior(normal(0, 3), class = sd),
  prior(lkj(2), class = cor)
)
```


```{r maximal bmm for N170 E2 high}

# fit bmm if bmm_n170.RData is not available
bmm_N170_high_file <- file.path(folder_bmm, "bmm_N170_high.RData")

if (!file.exists(bmm_N170_high_file)) {
  bmm.N170.high <- brm(MeanAmp ~ Category * Hemisphere * DuraBlock +
                         (1 + Category * Hemisphere * DuraBlock | SubjCode) +
                         (1 + Hemisphere * DuraBlock | Stimuli),
                       data = df.erp.N170.high.E2,
                       prior = prior.N170.high,
                       chains = 8,
                       warmup = 2000,
                       iter = 10000,
                       control = list(adapt_delta = 0.99),
                       save_all_pars = TRUE)
  
  save(bmm.N170.high, file = bmm_N170_high_file)
} else {
  load(bmm_N170_high_file)
}

summary(bmm.N170.high)
```

```{r}
# calculate the median and HDI
bmm.N170.high %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  median_hdi() %>% 
  rename(median = .value)
```

```{r}
plot(bmm.N170.high, pars = "^b_", ask = FALSE, N = 4, newpage = FALSE)
```


#### Estimated marginal means (median)
```{r}
# median and hdi in each condition
emm.bmm.N170.high <- emmeans(bmm.N170.high, ~ DuraBlock + Category + Hemisphere)
summary(emm.bmm.N170.high)
```

```{r}
# simple effect analysis
emm.bmm.N170.high %>%
  contrast(method = "pairwise", simple = "each", combine = TRUE) 
```

```{r}
# test the face-specific effects
contrast(emmeans(bmm.N170.high, ~ Category + DuraBlock | Hemisphere), 
         interactio = "pairwise")
```

#### Posterior distributions of parameters of interests
##### Distributions of DuraBlock
```{r fig.height=6, fig.width=10}
df_emm_db <- emm.bmm.N170.high %>% 
  gather_emmeans_draws() %>% 
  filter(Category == "face") %>% 
  mutate(Count = n())

df_emm_db_mh <- emm.bmm.N170.high %>% 
  gather_emmeans_draws() %>% 
  filter(Category == "face") %>% 
  median_hdi()

hemi_lab <- c("left", "right")
names(hemi_lab) <- c("Left", "Right")
con_lab <- c("17ms_half1 ", 
             "17ms_half2 ",
             "200ms_half2")
names(con_lab) <- c("17_1", "17_2", "200_2")
  
posterior_db <- ggplot(df_emm_db) + 
  geom_density(aes(x = .value), fill = "grey80") +
  geom_vline(xintercept = 0, linetype = "dashed", size = 0.75, color = "gray30") +
  geom_vline(data = df_emm_db_mh, aes(xintercept = .value), linetype = "dashed", color = "#0094EA", size = 1) +
  geom_errorbarh(data = df_emm_db_mh, aes(y = 0, xmin = .lower, xmax = .upper, height = .15), color = "#0094EA", size = 1.5) + 
  facet_grid(DuraBlock ~ Hemisphere,
             labeller = labeller(Hemisphere = hemi_lab, DuraBlock = con_lab)) +
  xlab(expression(paste("N170 Amplitudes (", mu, "V)"))) +
  ylab("Density") +
  theme_bw() +
  theme(
    text = element_text(size = 16),
    axis.title = element_text(size = 20), 
    axis.text = element_text(size = 18), # the size of the texts in plot
    legend.title=element_text(size=24),
    legend.text=element_text(size=18),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=20, lineheight=1),
    strip.text.y.right = element_text(angle = 0, size=16),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave("posterior_db.png", posterior_db, width = 10, height = 6)

posterior_db

```

##### Differences among DuraBlock
```{r fig.height=6, fig.width=10}
df_emm_post <- pairs(emm.bmm.N170.high, simple = "DuraBlock") %>% 
  gather_emmeans_draws() %>% 
  filter(Category == "face") %>% 
  mutate(Count = n())

df_emm_post_mh <- pairs(emm.bmm.N170.high, simple = "DuraBlock") %>% 
  gather_emmeans_draws() %>% 
  filter(Category == "face") %>% 
  median_hdi()

hemi_lab <- c("left", "right")
names(hemi_lab) <- c("Left", "Right")
con_lab <- c("17ms_half1  \nvs.\n17ms_half2 ", 
             "17ms_half1  \nvs.\n200ms_half2",
             "17ms_half2  \nvs.\n200ms_half2")
names(con_lab) <- c("17_1 - 17_2", "17_1 - 200_2", "17_2 - 200_2")
  
posterior_contra <- ggplot(df_emm_post) + 
  geom_density(aes(x = .value), fill = "grey80") +
  geom_vline(xintercept = 0, linetype = "dashed", size = 0.75, color = "gray30") +
  geom_vline(data = df_emm_post_mh, aes(xintercept = .value), linetype = "dashed", color = "#0094EA", size = 1) +
  geom_errorbarh(data = df_emm_post_mh, aes(y = 0, xmin = .lower, xmax = .upper, height = .15), color = "#0094EA", size = 1.5) + 
  facet_grid(contrast ~ Hemisphere,
             labeller = labeller(Hemisphere = hemi_lab, contrast = con_lab)) +
  # scale_y_continuous(breaks = c(0, 0.5, 1), limits = c(-0.1, 1.4)) +
  xlab(expression(paste("N170 Amplitudes (", mu, "V)"))) +
  ylab("Density") +
  theme_bw() +
  theme(
    text = element_text(size = 16),
    axis.title = element_text(size = 20), 
    axis.text = element_text(size = 18), # the size of the texts in plot
    legend.title=element_text(size=24),
    legend.text=element_text(size=18),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=20, lineheight=1),
    strip.text.y.right = element_text(angle = 0, size=16),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave("posterior_contra_bmm.png", posterior_contra, width = 10, height = 6)

posterior_contra

```


##### Face-specific differences among DuraBlock
```{r fig.height=6, fig.width=10}
df_emm_spec_post <- contrast(emm.bmm.N170.high, interaction = "pairwise", by = "Hemisphere") %>% 
  gather_emmeans_draws() %>% 
  mutate(Count = n())

df_emm_spec_post_mh <- pairs(emm.bmm.N170.high, interaction = "pairwise", by = "Hemisphere") %>% 
  gather_emmeans_draws() %>% 
  median_hdi()

hemi_lab <- c("left", "right")
names(hemi_lab) <- c("Left", "Right")
con_lab <- c("17ms_half1  \nvs.\n17ms_half2 ", 
             "17ms_half1  \nvs.\n200ms_half2",
             "17ms_half2  \nvs.\n200ms_half2")
names(con_lab) <- c("17_1 - 17_2", "17_1 - 200_2", "17_2 - 200_2")
  
posterior_contra_spec <- ggplot(df_emm_spec_post) + 
  geom_density(aes(x = .value), fill = "grey80") +
  geom_vline(xintercept = 0, linetype = "dashed", size = 0.75, color = "gray30") +
  geom_vline(data = df_emm_spec_post_mh, aes(xintercept = .value), linetype = "dashed", color = "#0094EA", size = 1) +
  geom_errorbarh(data = df_emm_spec_post_mh, aes(y = 0, xmin = .lower, xmax = .upper, height = .15), color = "#0094EA", size = 1.5) + 
  facet_grid(DuraBlock_pairwise ~ Hemisphere,
             labeller = labeller(Hemisphere = hemi_lab, DuraBlock_pairwise = con_lab)) +
  scale_y_continuous(breaks = c(0, 0.5, 1)) + #, limits = c(-0.1, 1.3)
  xlab(expression(paste("N170 Amplitudes (", mu, "V)"))) +
  ylab("Density") +
  theme_bw() +
  theme(
    text = element_text(size = 16),
    axis.title = element_text(size = 20), 
    axis.text = element_text(size = 18), # the size of the texts in plot
    legend.title=element_text(size=24),
    legend.text=element_text(size=18),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=20, lineheight=1),
    strip.text.y.right = element_text(angle = 0, size=16),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave("posterior_contra_spec_bmm.png", posterior_contra_spec, width = 10, height = 6)

posterior_contra_spec

```

#### Posterior predictive check
In the posterior predictive check plots, the black line denotes the median of the data in this study and the the distribution depicts the predictive values based on the model (i.e., `bmm.N170.high`).
```{r}
df_high_pred <- posterior_predict(bmm.N170.high, nsamples =  1000) %>% 
  array_branch(margin = 1) %>% 
  map_dfr(function(x) {
    df.erp.N170.high.E2 %>% 
      mutate(MeanAmp = x)
  }, .id = "iter") %>% 
  mutate(iter = as.numeric(iter))

tt <- lapply(levels(df.erp.N170.high.E2$SubjCode), function(x) {
  
  df_high_pred_sum <- df_high_pred %>% 
    filter(SubjCode == x) %>%
    group_by(iter, Hemisphere, Category, DuraBlock) %>% 
    summarize(medianAmp = median(MeanAmp))
  
  df_high_obs_sum <- df.erp.N170.high.E2 %>% 
    filter(SubjCode == x) %>%
    group_by(Hemisphere, Category, DuraBlock) %>% 
    summarize(medianAmp = median(MeanAmp))
  
  ggplot(df_high_pred_sum, aes(medianAmp)) +
    geom_histogram(alpha=.5, bins = 40) +
    geom_vline(aes(xintercept= medianAmp),data= df_high_obs_sum) +
    facet_grid(DuraBlock ~ Hemisphere + Category, scales = "free") +
    ggtitle(x) +
    NULL
})

tt

```

#### N170 for faces with 17ms and 200ms (left hemisphere)
##### Bayesian mixed models
```{r}
# manually set the backward difference coding
df.N170.lface <- {
  df.erp.N170.high.E2 %>% 
    filter(Category == "face",
           Hemisphere == "Left") %>% 
    mutate(D1B2_D1B1 = ifelse(DuraBlock == "17_1", -2/3, 1/3),
           D2B2_D1B2 = ifelse(DuraBlock == "200_2", 2/3, -1/3))
}

bmm_N170_high_lface_file <- file.path(folder_bmm, "bmm_N170_high_lface.RData")
if (!file.exists(bmm_N170_high_lface_file)) {
  bmm.N170.high.lface <- brm(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
                               (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                               (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                             data = df.N170.lface,
                             prior = prior.N170.high,
                             chains = 8,
                             warmup = 1000,
                             iter = 30000,
                             control = list(adapt_delta = 0.9),
                             save_all_pars = TRUE)
  
  save(bmm.N170.high.lface, file = bmm_N170_high_lface_file) 
} else {
  load(bmm_N170_high_lface_file)
}

summary(bmm.N170.high.lface)

```

```{r}
bmm.N170.high.lface %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  median_hdi()
```


```{r}
plot(bmm.N170.high.lface, pars = "^b_", ask = FALSE)
```


##### The null model
In the null model, `D2B2_D1B2` is forced to be 0, i.e., `D2B2_D1B2` will not be included in the model.
```{r}

bmm_N170_lface_null_file <- file.path(folder_bmm, "bmm_N170_lface_null.RData")
if (!file.exists(bmm_N170_lface_null_file)) {
  bmm_N170_lface_null <- brm(MeanAmp ~ D1B2_D1B1 + 
                               (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                               (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                             data = df.N170.lface,
                             prior = prior.N170.high,
                             chains = 8,
                             warmup = 1000,
                             iter = 30000,
                             control = list(adapt_delta = 0.9),
                             save_all_pars = TRUE)
  save(bmm_N170_lface_null, file = bmm_N170_lface_null_file)
} else {
  load(bmm_N170_lface_null_file)
}

lml_lface_null <- bridge_sampler(bmm_N170_lface_null, silent = TRUE)
```


```{r}
lml.N170.high.lface <- bridge_sampler(bmm_N170_lface_null, silent = TRUE)
BF01.N170.lface <- bayes_factor(lml_lface_null, lml.N170.high.lface)

BF01.N170.lface
```


##### Bayes factor for models with different prior standard deviations

```{r}
# get_prior(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
#                             (1 + DuraBlock | SubjCode) +
#                             (1 + DuraBlock | Stimuli),
#                           data = df.N170.lface)

BFs_N170_lface_file <- file.path(folder_bmm, "BFs_N170_lface.RData")
if (!file.exists(BFs_N170_lface_file)) {
  prior_sd <- c(0.05, 0.1, 0.2, 0.5, 0.75, 1, 2, 5) 
  BFs <- map_dfr(prior_sd, function(psd) {
    gc() # force R "garbage collector" so that we don't run out of memory 
    
    print(paste0("Fitting model with psd:", psd))
    
    thefit <- brm(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
                    (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                    (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                  data = df.N170.lface,
                  prior =c(prior.N170.high,
                           set_prior(paste0("normal(0,",psd ,")"), class = "b", coef = "D2B2_D1B2")), 
                  chains = 8,
                  warmup = 1000,
                  iter = 30000,
                  control = list(adapt_delta = 0.9), 
                  save_all_pars = TRUE)
    
    lml_lface_alt <- bridge_sampler(thefit, silent = TRUE)
    tibble(beta_sd = psd, 
           BF = bayes_factor(lml_lface_null, lml_lface_alt)$bf) 
  })
  
  BFs_N170_lface <- BFs %>% 
    mutate(BF01 = BF,
           BF10 = 1/BF)
  
  save(BFs_N170_lface, file = BFs_N170_lface_file)
  
} else {
  load(BFs_N170_lface_file) 
}


BFs_N170_lface 
```

```{r BF plots for left N170}
breaks <- c(1/50 , 1 / 20, 1 / 10, 1 / 3, 1, 3, 5, 10, 20)
curve <- as.data.frame(spline(BFs_N170_lface$beta_sd, BFs_N170_lface$BF01))
ggplot(BFs_N170_lface, aes(x = beta_sd, y = BF)) +
  geom_point(size =2) +
  ## geom_line(data = curve, aes(x = x, y = y))+
  geom_line() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  ## theme_bw() +
  scale_x_continuous("Normal prior width (SD)\n") +
  scale_y_log10("BF01", breaks = breaks, labels = MASS::fractions(breaks)) +
  coord_cartesian(ylim = c(1 / 30, 30)) +
  annotate("text", x =1, y= 18, label = "Evidence in favor of H0", size =5)+
  annotate("text", x =1, y= 1/18, label = "Evidence in favor of H1", size =5) +
  theme(axis.text.y = element_text(size = 8)) +
  ggtitle("Bayes factors") +
  NULL
```

```{r}
# 
# BFs_N170_lface_B21_file <- file.path(folder_bmm, "BFs_N170_lface_B21.RData")
# load(BFs_N170_lface_B21_file) 
# 
# BFs_N170_lface_B21 
```


#### N170 for faces with 17ms and 200ms (right hemisphere)
##### Bayesian mixed models
```{r}
df.N170.rface <- {
  df.erp.N170.high.E2 %>% 
    filter(Category == "face",
           Hemisphere == "Right") %>% 
    mutate(D1B2_D1B1 = ifelse(DuraBlock == "17_1", -2/3, 1/3),
           D2B2_D1B2 = ifelse(DuraBlock == "200_2", 2/3, -1/3))
}

bmm_N170_high_rface_file <- file.path(folder_bmm, "bmm_N170_high_rface.RData")
if (!file.exists(bmm_N170_high_rface_file)) {
  bmm.N170.high.rface <- brm(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
                               (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                               (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                             data = df.N170.rface,
                             prior = prior.N170.high,
                             chains = 8,
                             warmup = 1000,
                             iter = 30000,
                             control = list(adapt_delta = 0.9),
                             save_all_pars = TRUE)
  
  save(bmm.N170.high.rface, file = bmm_N170_high_rface_file)
  
} else {
  load(bmm_N170_high_rface_file)
}

summary(bmm.N170.high.rface)

```

```{r}
bmm.N170.high.rface %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  median_hdi()
```

```{r}
summary(emmeans(bmm.N170.high.rface, ~ D1B2_D1B1 + D2B2_D1B2))
```


```{r}
plot(bmm.N170.high.rface, pars = "^b_", ask = FALSE)
```

```{r}
pp_check(bmm.N170.high.rface)
```


##### The null model
```{r}

bmm_N170_rface_null_file <- file.path(folder_bmm, "bmm_N170_rface_null.RData")
if (!file.exists(bmm_N170_rface_null_file)) {
  bmm_N170_rface_null <- brm(MeanAmp ~ D1B2_D1B1 + 
                               (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                               (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                             data = df.N170.rface,
                             prior = prior.N170.high,
                             chains = 8,
                             warmup = 1000,
                             iter = 30000,
                             control = list(adapt_delta = 0.9),
                             save_all_pars = TRUE)
  save(bmm_N170_rface_null, file = bmm_N170_rface_null_file)
} else {
  load(bmm_N170_rface_null_file)
}

lml_rface_null <- bridge_sampler(bmm_N170_rface_null, silent = TRUE)
```


```{r}
lml.N170.high.rface <- bridge_sampler(bmm.N170.high.rface, silent = TRUE)
BF01_N170_rface <- bayes_factor(lml_rface_null, lml.N170.high.rface)

BF01_N170_rface

```

##### Bayes factor for models with different prior standard deviations
```{r}

# get_prior(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
#                             (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
#                             (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
#                           data = df.N170.rface)

BFs_N170_rface_file <- file.path(folder_bmm, "BFs_N170_rface.RData")
if (!file.exists(BFs_N170_rface_file)) {
  prior_sd <- c(0.05, 0.1, 0.2, 0.5, 0.75, 1, 2, 5) 
  BFs <- map_dfr(prior_sd, function(psd) {
    gc() # force R "garbage collector" so that we don't run out of memory 
    
    print(paste0("Fitting model with psd:", psd))
    
    thefit <- brm(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
                    (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                    (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                  data = df.N170.rface,
                  prior = c(prior.N170.high,
                            set_prior(paste0("normal(0,",psd ,")"), class = "b", coef = "D2B2_D1B2")), 
                  chains = 8,
                  warmup = 1000,
                  iter = 30000,
                  control = list(adapt_delta = 0.9), 
                  save_all_pars = TRUE)
    
    lml_rface_alt <- bridge_sampler(thefit, silent = TRUE)
    tibble(beta_sd = psd, 
           BF = bayes_factor(lml_rface_null, lml_rface_alt)$bf) 
  })
  
  BFs_N170_rface <- BFs %>% 
    mutate(BF01 = BF,
           BF10 = 1/BF)
  
  save(BFs_N170_rface, file = BFs_N170_rface_file)
  
} else {
  load(BFs_N170_rface_file)
}

BFs_N170_rface

```

```{r BF plots for right N170}
breaks <- c(1/50 , 1 / 20, 1 / 10, 1 / 3, 1, 3, 5, 10, 20)
curve <- as.data.frame(spline(BFs_N170_rface$beta_sd, BFs_N170_rface$BF01))
ggplot(BFs_N170_rface, aes(x = beta_sd, y = BF)) +
  geom_point(size =2) +
  ## geom_line(data = curve, aes(x = x, y = y))+
  geom_line() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  ## theme_bw() +
  scale_x_continuous("Normal prior width (SD)\n") +
  scale_y_log10("BF01", breaks = breaks, labels = MASS::fractions(breaks)) +
  coord_cartesian(ylim = c(1 / 30, 30)) +
  annotate("text", x =1, y= 18, label = "Evidence in favor of H0", size =5)+
  annotate("text", x =1, y= 1/18, label = "Evidence in favor of H1", size =5) +
  theme(axis.text.y = element_text(size = 8)) +
  ggtitle("Bayes factors") +
  NULL
```

#### Face-specific N170 for 17ms and 200ms (left hemisphere)
##### Bayesian mixed models
```{r}
# manually set the backward difference coding
df.N170.lfs <- {
  df.erp.N170.high.E2 %>% 
    filter(Hemisphere == "Left") %>% 
    mutate(D1B2_D1B1 = ifelse(DuraBlock == "17_1", -2/3, 1/3),
           D2B2_D1B2 = ifelse(DuraBlock == "200_2", 2/3, -1/3),
           
           Cate_D1B2_D1B1 = Cate_C * D1B2_D1B1,
           Cate_D2B2_D1B2 = Cate_C * D2B2_D1B2)
}

bmm_N170_high_lfs_file <- file.path(folder_bmm, "bmm_N170_high_lfs.RData")
if (!file.exists(bmm_N170_high_lfs_file)) {
  bmm.N170.high.lfs <- brm(MeanAmp ~ Cate_C + D1B2_D1B1 + D2B2_D1B2 + 
                             Cate_D1B2_D1B1 + Cate_D2B2_D1B2 + # Category * DuraBlock +
                               (1 + Cate_C + D1B2_D1B1 + D2B2_D1B2 + 
                             Cate_D1B2_D1B1 + Cate_D2B2_D1B2 | SubjCode) +
                               (1 + Cate_C + D1B2_D1B1 + D2B2_D1B2 + 
                             Cate_D1B2_D1B1 + Cate_D2B2_D1B2 | Stimuli),
                             data = df.N170.lfs,
                             prior = prior.N170.high,
                             chains = 8,
                             warmup = 1000,
                             iter = 30000,
                             control = list(adapt_delta = 0.9),
                             save_all_pars = TRUE)
  
  save(bmm.N170.high.lfs, file = bmm_N170_high_lfs_file) 
} else {
  load(bmm_N170_high_lfs_file)
}

summary(bmm.N170.high.lfs)
```


```{r}
bmm.N170.high.lfs %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  median_hdi()
```


```{r}
plot(bmm.N170.high.lfs, pars = "^b_", ask = FALSE)
```


##### The null model
In the null model, `D2B2_D1B2` is forced to be 0, i.e., `D2B2_D1B2` will not be included in the model.
```{r}

bmm_N170_lfs_null_file <- file.path(folder_bmm, "bmm_N170_lfs_null.RData")
if (!file.exists(bmm_N170_lfs_null_file)) {
  bmm_N170_lfs_null <- brm(MeanAmp ~ D1B2_D1B1 + 
                               (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                               (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                             data = df.N170.lfs,
                             prior = prior.N170.high,
                             chains = 8,
                             warmup = 1000,
                             iter = 30000,
                             control = list(adapt_delta = 0.9),
                             save_all_pars = TRUE)
  save(bmm_N170_lfs_null, file = bmm_N170_lfs_null_file)
} else {
  load(bmm_N170_lfs_null_file)
}

lml_lfs_null <- bridge_sampler(bmm_N170_lfs_null, silent = TRUE)
```


```{r}
lml.N170.high.lfs <- bridge_sampler(bmm_N170_lfs_null, silent = TRUE)
BF01.N170.lfs <- bayes_factor(lml_lfs_null, lml.N170.high.lfs)

BF01.N170.lfs
```


##### Bayes factor for models with different prior standard deviations

```{r}
# get_prior(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
#                             (1 + DuraBlock | SubjCode) +
#                             (1 + DuraBlock | Stimuli),
#                           data = df.N170.lfs)

BFs_N170_lfs_file <- file.path(folder_bmm, "BFs_N170_lfs.RData")
if (!file.exists(BFs_N170_lfs_file)) {
  prior_sd <- c(0.05, 0.1, 0.2, 0.5, 0.75, 1, 2, 5) 
  BFs <- map_dfr(prior_sd, function(psd) {
    gc() # force R "garbage collector" so that we don't run out of memory 
    
    print(paste0("Fitting model with psd:", psd))
    
    thefit <- brm(MeanAmp ~ D1B2_D1B1 + D2B2_D1B2 +
                    (1 + D1B2_D1B1 + D2B2_D1B2 | SubjCode) +
                    (1 + D1B2_D1B1 + D2B2_D1B2 | Stimuli),
                  data = df.N170.lfs,
                  prior =c(prior.N170.high,
                           set_prior(paste0("normal(0,",psd ,")"), class = "b", coef = "D2B2_D1B2")), 
                  chains = 8,
                  warmup = 1000,
                  iter = 30000,
                  control = list(adapt_delta = 0.9), 
                  save_all_pars = TRUE)
    
    lml_lfs_alt <- bridge_sampler(thefit, silent = TRUE)
    tibble(beta_sd = psd, 
           BF = bayes_factor(lml_lfs_null, lml_lfs_alt)$bf) 
  })
  
  BFs_N170_lfs <- BFs %>% 
    mutate(BF01 = BF,
           BF10 = 1/BF)
  
  save(BFs_N170_lfs, file = BFs_N170_lfs_file)
  
} else {
  load(BFs_N170_lfs_file) 
}


BFs_N170_lfs 
```

```{r BF plots for left N170}
breaks <- c(1/50 , 1 / 20, 1 / 10, 1 / 3, 1, 3, 5, 10, 20)
curve <- as.data.frame(spline(BFs_N170_lfs$beta_sd, BFs_N170_lfs$BF01))
ggplot(BFs_N170_lfs, aes(x = beta_sd, y = BF)) +
  geom_point(size =2) +
  ## geom_line(data = curve, aes(x = x, y = y))+
  geom_line() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  ## theme_bw() +
  scale_x_continuous("Normal prior width (SD)\n") +
  scale_y_log10("BF01", breaks = breaks, labels = MASS::fractions(breaks)) +
  coord_cartesian(ylim = c(1 / 30, 30)) +
  annotate("text", x =1, y= 18, label = "Evidence in favor of H0", size =5)+
  annotate("text", x =1, y= 1/18, label = "Evidence in favor of H1", size =5) +
  theme(axis.text.y = element_text(size = 8)) +
  ggtitle("Bayes factors") +
  NULL
```


# Appendix

## Model selection procedure

For the analysis for every dependent variable, an optimal model was obtained by the following general steps:

1. **Maximum Model**: a maximum model with all fixed and random factors was built. 
2. **ZCP Model**: a zero-correlated-parameter (zcp) model based on the maximum model is built. The only difference between zcp and maximum models is that the correlations between random effects are forced to be zero in the zcp model.
3. **Reduced Model**: the random effects which are not supported by the data will be removed from the zcp model. The function `step(fit, fixed.reduce = FALSE)` from `library(lmerTest)` is used for this step. The algorithm could be found [here](#stepfun).
4. **Extended Model**: extending the reduced model with correlation parameters between the remaining random effects.
5. **Pruning Model**: pruning low correlation parameters. (Usually I don't do this.)

More details about this whole process chould be found here: Bates, D., Kliegl, R., Vasishth, S., & Baayen, H. (2015). Parsimonious Mixed Models. Retrieved from http://arxiv.org/abs/1506.04967.

## Algorithm of function `step` {#stepfun}
The outline of the algorithm of `step(fit, reduce.fixed = false)` function is: 

>  Simplification of the random effects structure:
>
>   1. Let M be the linear mixed effects model specified by a user. 
>
>   2. If there are random effects in M then go to 3, otherwise stop. 
>
>   3. For each random effect ri in M do: 
>       (a) Create a reduced model Mi by eliminating ri from M. 
>
>       (b) Calculate pi, the p value from the likelihood ratio test of comparing M to Mi. 
>
>       (c) Save pi and Mi.
>
>   4. Find pmax; the maximum of all pi and let Mmax denote the corresponding model. 
>
>   5. Set M to Mmax. If pmax is guesser than α level then go back to 3, otherwise stop.

More deatils could be found: Kuznetsova, A., Brockhoff, P. B., & Christensen, R. H. B. (2017). lmerTest Package: Tests in Linear Mixed Effects Models. Journal of Statistical Software, 82(13), 1-26. http://doi.org/10.18637/jss.v082.i13 **Page 8**


## Stimuli specific effects
```{r}

# 28 participants in total

resp.stim <- {
  clean_beha_205 %>% 
    # filter(Duration == "17", Resp == "1") %>% 
    mutate(isKey1 = as.numeric(Resp == "1"),
           Type_Category = paste(Type, Category, sep = "-")) %>% 
    group_by(Stimuli, Duration, Type_Category) %>% 
    summarize(avgCount = mean(isKey1)) 
  
}

ggplot(resp.stim, aes(x = Stimuli, y = avgCount, fill = Type_Category)) +
  geom_col() +
  facet_grid(Duration ~ .) +
  labs(title = "Averaged percentage of being responsed as 'Key 1' for each stimuli",
       y = "Percentage") +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        text = element_text(size = 10),
        axis.title = element_text(size = 16), 
        axis.text = element_text(size = 15), # the size of the texts in plot
        # axis.text.x = element_text(angle = 45, vjust = 0.5),
        legend.title=element_text(size=16),
        legend.text=element_text(size=16),
        # legend.position = "bottom",
        legend.key.width = unit(1.2, "cm"),
        plot.title = element_text(lineheight=.8, face="bold", size = 17),
        strip.text = element_text(face="bold", size=15, lineheight=5.0),
        strip.background = element_rect(fill="white", colour="white", size=1),
        strip.placement = "outside",
        legend.position = "bottom") 
```


```{r}

resp.stim.1 <- {
  clean_beha_205 %>% 
    mutate(isKey1 = as.numeric(Resp == "1")) %>% 
    filter(Type == "intact", Category == "face") %>% 
    group_by(Stimuli, SubjCode, Duration) %>% 
    summarize(avgCount = mean(isKey1)) %>% 
    ungroup() 
}

resp.stim.1.17 <- {
  resp.stim.1 %>% 
    filter(Duration == "17") %>% 
    select(-Duration) %>% 
    spread(Stimuli, avgCount)
}

resp.stim.1.17 <- data.matrix(select(resp.stim.1.17, -SubjCode))

resp.stim.1.200 <- {
  resp.stim.1 %>% 
    filter(Duration == "200") %>% 
    select(-Duration) %>% 
    spread(Stimuli, avgCount)
}

resp.stim.1.200 <- data.matrix(select(resp.stim.1.200, -SubjCode))


library(plotly)

heatmap_17 <- plot_ly(z = data.matrix(resp.stim.1.17), type = "heatmap", name = "Figrename")
heatmap_200 <- plot_ly(z = data.matrix(resp.stim.1.200), type = "heatmap", name = "Figrename")

```

# Versions of packages used
```{r versions}
# rstudioapi::versionInfo()
sessionInfo()
```
