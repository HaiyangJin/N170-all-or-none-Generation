---
title: "P203 Subjective Perception and ERP Amplitude (the N170)"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output:
  html_document:
    df_print: paged
    number_sections: true
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: false
    includes:
      after_body: Utilities/footer.html
---

# General introduction

## Introduction

**Linear Mixed Model** were used.

## Experiment design

* **Independent variables**:
+ Stimulus Type (`Type`: *intact* vs. *scrambled*)
+ Stimulus Category (`Category`: *faces* vs. *houses*)
+ Hemisphere (`Hemisphere`: *left* vs. *right*)
+ Duration (`Duration`: *17* vs. *200*)

## Preparations
```{r, echo=FALSE, include=FALSE}
# knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(echo = TRUE) # show the code for this chunk
options(width = 140)  # set the maximum width of the html output
```

```{r setup and load the related libraries, message=FALSE}
## load libraries
library(tidyverse)
library(magrittr)
library(lme4)
library(lmerTest) 
library(emmeans)

# options for calculating estimated marginal means
# lmer.df = c("kenward-roger", "satterthwaite", "asymptotic")
emm_options(lmer.df = "satterthwaite", 
            lmerTest.limit = 1e6,
            opt.digits = FALSE)  # , pbkrtest.limit =, disable.pbkrtest = FALSE

```

```{r foldes and load R files, include=FALSE}
set.seed(42)

# folders
folder_R <- "R"
folder_data <- "data"
folder_nesi <- "NeSI"
folder_bmm <- "bmmfit"

# load all the R files
sapply(list.files(folder_R, "*.R", full.names = TRUE, recursive = TRUE), source)

```

```{r settings}
# general setting
saveCSV <- FALSE
ratio_count <- 0.8
RT_min <- 200  # minimum response times

# set up the theme for plot and rainclound plot
plot_theme <- {
  general_theme +
    theme(legend.position = "right")
}

erp_theme <- {
  general_theme +
    theme(legend.position = "bottom")
}

ylimit_p1 <- c(2.5, -0.5)
ylimit_n170 <- c(1.5, -5.5)  # y axis for plotting N170 amplitude

resp_labels = c("sure faces", "not sure faces", "guessing", "not sure houses", "sure houses")

```


# Hypotheses
Previous studies showed that the N170 amplitudes evoked by faces preseneted for longer durations were larger:
```{r fig.height=3, fig.width=2}
Duration <- c("17", "200")
Amplitudes <- c(-2.5, -5)
Hypotheses <- rep("means", 2)

df_lit <- data_frame(Duration, Amplitudes, Hypotheses)

plot_lit <- {
  ggplot(data = df_lit, aes(y = Amplitudes, x = Duration, fill = Duration)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(color = "black") +
    facet_grid(. ~ Hypotheses) +
    scale_fill_manual(values = c(gray(.7), gray(.3))) +
    scale_y_reverse(limits =c(0, -5.5), breaks = seq(0, -5, -1), expand= c(0, 0)) +  # set the limit for y axis
    geom_hline(yintercept = -2.5, linetype = "dashed", color = "red", size = 1) +
    labs(x = "", y = expression(paste("Amplitudes (", mu, "V)"))) +  # set the names for main, x and y axises ,  title = "Means", 
    # theme_bw() +
    general_theme +
    theme( # strip.text = element_text(color = "white"),
      legend.position = "none",
      axis.line = element_line(size = 3, colour = "black"))
}

plot_lit
```

There are two possible explainations for the aggregated mean amplitudes:
```{r}

Duration <- rep(c(rep("17", 5), rep("200", 5) ), 2)
Amplitudes <- c(c(rep(-2.5, 5), rep(-5, 5)), c(rep(-.83, 3), rep(-5, 7)))
TrialNum <- rep(as.character(rep(c(1:5), 2)), 2)
Hypotheses <- c(rep("Possibility 1", 10), rep("Possibility 2", 10))

df_st <- data_frame(Duration, Amplitudes, TrialNum, Hypotheses)

plot_st <- {
  ggplot(data = df_st, aes(y = Amplitudes, x = Duration, fill = Duration, color = TrialNum)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge") +
    scale_fill_manual(values = c(gray(.7), gray(.3))) +
    scale_color_manual(values = rep("black", 5)) +
    facet_grid(. ~ Hypotheses) +
    geom_hline(yintercept = -2.5, linetype = "dashed", color = "red", size = 1) +
    scale_y_reverse(limits =c(0, -5.5), breaks = seq(0, -5, -1), expand= c(0, 0)) +  # set the limit for y axis
    labs(x = "Duration (ms)") +  # set the names for main, x and y axises , title = "At the single-trial level:", , y = expression(paste("Amplitudes (", mu, "V)"))
    theme_bw() +
    general_theme +
    theme(legend.position = "none",
          axis.title.y = element_blank(),
          axis.line = element_line(size = 3, colour = "black"))
}

plot_st
```


```{r combine the aggregated mean amp plots and the explanation plots, include=FALSE}

# library(ggpubr)
# plot.hypo <- ggarrange(plot_lit, plot_st, widths = c(1.1, 4))
# 
# # ggsave('plot_hypo.pdf', plot.hypo, width = 7, height = 3)
# 
# plot_hypo
```

# Brief introduction to the analysis

## Equivalence tests
In this study, we do predict that there will be no differences between some conditions. For example, we expect that N170 amplitudes for faces presented for various durations are comparable as long as they are perceived with high subjective confidence. Thus, we employ Equivalence tests to explore if the differences are equivalent to a null region, which we defined as [-0.5, 0.5] in this study. Esentially, the equivalence test performs two one-sided tests to examine if the differences are smaller than the upper boundary of the region and larger than the lower boundary. 
By performing the conventional null hypothesis significance tests and the equivalence tests, there are (at least) five scenarios for the results:
```{r possible results, fig.height=4.7, fig.width=8}
# equivalence interval
delta_null <- 0.5  # the equivalent interval will be [-delta_null, delta_null]
CI_size = .8

df_equi <- tibble(
  Scenarios = paste("Scenario", 1:6),
  CI_low = c(delta_null-.15, -delta_null-.5, -delta_null+.15, delta_null-.6, -delta_null-.25, -delta_null-.1),
  CI_upp = CI_low + c(rep(CI_size, 5), 1.3)
) %>% 
  mutate(Scenarios = factor(Scenarios),
         Scenarios = factor(Scenarios, levels = rev(levels(Scenarios))))

gg_equi <- ggplot(df_equi, aes(xmin = CI_low, xmax = CI_upp, y = Scenarios)) +
  geom_errorbarh(height = .5, color = c("red", "red", "blue", rep("black", 3)), size = 1) + 
  geom_vline(xintercept = 0, linetype = "longdash") +
  geom_vline(xintercept = c(-delta_null, delta_null), linetype = "dashed", color = "gray30") +
  scale_x_continuous(limits = c(-1.15, 1.15), breaks = c(-delta_null, 0, delta_null)) +
  xlab(expression(paste("Amplitudes (", mu, "V)"))) +
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 15), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=16),
    legend.text=element_text(size=16),
    # legend.position = "bottom",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=15, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
)

# ggsave("equivalence_test.png", gg_equi, width = 8, height = 4.7)

gg_equi
```


# Behavior results
```{r load behavioral results of 205}
raw_beha_205 <- {
  "E205_35_Behavior.csv" %>% 
    file.path(folder_data, .) %>% 
    read_csv()
}
```


```{r select certain rows and columns from the data, and calculate the Z value for reaction times (205)}
clean_beha_205 <- {
  raw_beha_205 %>%
    filter(`Procedure[Trial]` == "expProc") %>% # remove rows for practice and countdown
    select(ExperimentName, SubjCode = Subject, blockID, Block, Trial, Age, Sex, Handedness, Type = `stimCategory[Trial]`, Category = `FH[Trial]`, Duration = `stimDuration[Trial]`, ACC = `Resp.ACC[Trial]`, Resp.RT = `Resp.RT[Trial]`, Resp = `Resp.RESP[Trial]`, Stimuli = `stimName[Trial]`) %>% # select and rename the columns (remove unuseful columns)
    mutate(
      SubjCode = factor(paste("P", SubjCode, sep = "")), # save SubjCode as factor
      Type = substr(Type, 1, 1),
      Type = recode_factor(Type, "N" = "intact", "S" = "scrambled"), # rename the levels of Type
      Category = recode(Category, "hosue" = "house", "house" = "house", "face" = "face", .default = "face"), # rename "hosue" as "house"
      Duration = factor(Duration), # save Duration as factor
      Category = as.factor(Category),
      Resp = as.factor(Resp),
      blockID = as.factor(blockID)
    ) %>% 
    group_by(SubjCode, Type, Category, Duration, ACC) %>% # divide the data based on these conditions
    mutate(
      RT = Resp.RT + as.numeric(levels(Duration))[Duration],
      RT.Z = scale(RT), # calculate the Z value for reaction times within each group
      RT.Within3Z = ifelse(RT.Z <= 3 & RT.Z >= -3, 1, ifelse(RT.Z < -3 | RT.Z > 3, 0, NaN)) # if the Z values are between -3 and 3, will be marked as 1
    ) %>% 
    ungroup() # ungroup the data 
  
}

# behavior.tidyup
head(clean_beha_205, 10)

```

```{r check the number of trials for 205}
# check the number of trials for 205
sum.count.205 <- {
  clean_beha_205 %>% 
    group_by(SubjCode, Type, Category, Duration) %>% 
    summarize(Count_sum = n())
}

valid.count.205 <- {
  clean_beha_205 %>% 
    filter(RT > RT_min) %>% 
    group_by(SubjCode, Type, Category, Duration) %>% 
    summarize(Count = n()) %>% 
    right_join(sum.count.205, by = c("SubjCode", "Type", "Category", "Duration")) %>% 
    mutate(ratio = Count / Count_sum) %>% 
    filter(ratio > ratio_count) %$%
    SubjCode %>% 
    unique()
}

# remove the participants
clean_beha_205 %<>% filter(SubjCode %in% valid.count.205)

```


```{r remove participants whose performance in Key 1 was lower than 95%}
# remove participants whose performance in Key 1 was lower than 95%

valid.17 <- {
  clean_beha_205 %>%
    filter(Duration == 17, Resp == 1) %>% # Type == "intact",
    group_by(SubjCode, Duration, Resp) %>% # Type, 
    summarize(Accuracy = mean(ACC), Count = n()) %>% 
    filter(Accuracy > 0.95) %$%
    SubjCode
}


# clean_beha_205 %>%
#   filter(Duration == 17, Resp == 1) %>% # Type == "intact",
#   group_by(SubjCode, Duration, Resp) %>% # Type, 
#   summarize(Accuracy = mean(ACC), Count = n()) %>% 
#   filter(Accuracy < 0.95) %>% 
#   ungroup() %>% 
#   summarize(mean(Accuracy), min(Accuracy), max(Accuracy))  

clean_beha_205 %<>% filter(SubjCode %in% valid.17)



```

## Participant demographic information
```{r participant information E205}
subj.info.205 <- {
  clean_beha_205 %>% 
    select(SubjCode, Age, Sex, Handedness) %>% # select the columns of participant inforamtion
    distinct() # only keep the unique rows
}

subj.info.205

```

```{r}
mean(subj.info.205$Age)
range(subj.info.205$Age)

sum(subj.info.205$Sex == "female")
```

## Allocation of responses in each condition
```{r}
tmp.count <- {
  clean_beha_205 %>% 
    group_by(SubjCode, Type, Category, Duration) %>% 
    summarize(Count_sum = n())
}

avg.dist.long.205 <- {
  clean_beha_205 %>% 
    # mutate(RespRateFace = if_else(Category == "face", ACC, if_else(Category == "house", as.numeric(!ACC), NaN))) %>% 
    group_by(SubjCode, Type, Category, Duration, Resp) %>% 
    summarize(Count = n()) %>% 
    
    right_join(tmp.count, by = c("SubjCode", "Type", "Category", "Duration")) %>% 
    mutate(RespRate = Count / Count_sum) %>% 
    ungroup()
}

# descriptive statistics of accuracy for plotting
desc.dist.205 <- {
  avg.dist.long.205 %>%
    group_by(Type, Category, Duration, Resp) %>%
    summarize(Mean = mean(RespRate)
              , N = n()
              , SD = if_else(N > 1, sd(RespRate), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI_lo = Mean - SE * 1.96
              , CI_hi = Mean + SE * 1.96
              , Median = median(RespRate)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>% 
    ungroup() %>% 
    add_row(Type = "intact", Category = "house", Duration = "200", Resp = "2", Mean = 0, N = 0, SD = 0, SE = 0, SE.lo = 0,
            SE.hi = 0, CI_lo = 0, CI_hi = 0, Median = 0, Lower = 0, Upper = 0, .before = 17)
}

avg.dist.wide.205 <- {
  avg.dist.long.205 %>% 
    mutate(Conditions = paste(Type, Category, Duration, Resp, sep = "_")) %>% 
    select(SubjCode, Conditions, RespRate) %>% 
    spread(Conditions, RespRate)
}

```


```{r rainclound plot of the RT data E205, warning = FALSE}
desc.dist.205

dist.RainPlot.205 <- {
  ggplot(data = avg.dist.long.205, aes(y = RespRate, x = as.factor(Resp), fill = Category)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RespRate, color = Category), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RespRate), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.dist.205, aes(y = Mean, x = Resp, color = Category), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.dist.205, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(Type ~ Duration) +
    
    # facet_grid(. ~ Type, switch = "x") +  # create two panels to show data
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") + # palette = "RdBu"
    # scale_fill_brewer(palette = "Set1") + # palette = "RdBu"
    labs(title = "Reaction times for 205", x = "Stimulus Type", y = "Reaction times (ms)", fill = "Duration(ms)", color = "Duration(ms)") +  # set the names for main, x and y axises and the legend
    # scale_x_discrete(labels=resp_labels) +
    # coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot for reaction times, eval=FALSE, include=FALSE}
dist.RainPlot.205
```


```{r}

dura.labels <- c("17ms", "200ms")
names(dura.labels) <- c(17, 200)

dist.ColuPlot.205 <- {
  ggplot(data = desc.dist.205, aes(y = Mean, x = Resp, fill = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Type ~ Duration,
               labeller = labeller(Duration = dura.labels)) +
    geom_errorbar(mapping = aes(ymin = CI_lo, ymax = CI_hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "", x = "Responses", y = "Percentage", fill = "Category") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    erp_theme
}

dist.ColuPlot.205

```

## Percentage of face stimuli
```{r}
df_ratio_205 <- {
  clean_beha_205 %>%
    mutate(isFace = if_else(Category == "face", 1, 0)) %>%
    group_by(SubjCode, Type, Duration, Resp) %>%
    summarize(ratio = mean(isFace), Count = n())
}

desc_ratio_205 <- {
  df_ratio_205 %>%
    group_by(Type, Duration, Resp) %>%
    summarize(Mean = mean(ratio)
              , N = n()
              , SD = if_else(N > 1, sd(ratio), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI_lo = Mean - SE * 1.96
              , CI_hi = Mean + SE * 1.96
              , Median = median(ratio)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>%
    ungroup()
}

```

```{r }

rate.ColuPlot.205 <- {
  ggplot(data = desc_ratio_205, aes(y = Mean, x = Resp)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Type ~ Duration, 
               labeller = labeller(Duration = dura.labels)) +
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    # coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0), limits = c(-0.1, 1.15), breaks = seq(0, 1, 0.25)) +  # remove the space between columns and x axis
    labs(x = "Responses", y = "Percentage") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    plot_theme
}

rate.ColuPlot.205

```

Combine the two plots (for publication):
```{r eval=FALSE, include=FALSE, fig.asp=.5, fig.width = 5}
# combine the two behavior response plots

dist_ColuPlot_205 <- 
  ggplot(data = desc.dist.205, aes(y = Mean, x = Resp, fill = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
  geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
  facet_grid(Type ~ Duration,
             labeller = labeller(Duration = dura.labels)) +
  geom_errorbar(mapping = aes(ymin = CI_lo, ymax = CI_hi), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = c(1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
  scale_y_continuous(expand= c(0, 0), limits = c(-0.1, 1.15), breaks = seq(0, 1, 0.25)) +# remove the space between columns and x axis  
  labs(x = "Responses", y = "Percentage", fill = "Category") +  # set the names for main, x and y axises Subjective Responses for E205
  scale_fill_grey() +  # set the color for columns
  # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
  erp_theme +
  theme(legend.position = c(0.53, 0.3)) 

resp_ColuPlot_205 <- {
  ggplot(data = desc_ratio_205, aes(y = Mean, x = Resp)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Type ~ Duration, 
               labeller = labeller(Duration = dura.labels)) +
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    # coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0), limits = c(-0.1, 1.15), breaks = seq(0, 1, 0.25)) +  # remove the space between columns and x axis
    labs(x = "Responses", y = "Percentage") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    plot_theme
}
  
plot_two_response <- ggpubr::ggarrange(dist_ColuPlot_205, resp_ColuPlot_205, nrow = 1,
            widths = c(1, .7),
            labels = c("a", "b"),
            font.label = list(size = 24, face = "plain"))  # ratio between the two subplots)

ggsave('plot_two_response.png', plot_two_response, width = 10, height = 5)

```

# ERP amplitude analysis
## Load mean amplitude for single trials
The raw mean amplitude of each trial for all participants were loaded.
```{r load trial mean amplitude E2, message = FALSE}
# read the trial mean amplitude data
df.erp.E2 <- {
  "E205_MeanAmp.csv" %>% 
    file.path(folder_data, .) %>% 
    read_csv() %>% 
    substr_Event() %>% 
    filter(SubjCode %in% valid.17) %>% 
    mutate(SubjCode = as.factor(SubjCode),
           Hemisphere = as.factor(Hemisphere),
           urResponse = as.factor(urResponse),
           Stimuli = substr(stimName, 2, 6))
}

df.erp.E2 %>% 
  group_by(SubjCode, Stimuli, Hemisphere, Type, Category, Duration) %>% 
  summarize(count = n())

```

## Linear mixed model across responses

### Set the successive difference coding
```{r set the dummy coding for ERP data E2}
# dummy coding
df.erp.E2.all <- sdif_coding_P203_erp(df.erp.E2)
```


### Amplitudes of the P1
```{r erp df for the P1 E2}
# only keep the data for amplitudes of the P1 (correct and incorrect erps)
df.erp.P1.E2 <- {
  df.erp.E2.all %>% 
    filter(Component == "P1")
}

if (saveCSV) {
  output.erp.P1.E2 <- file.path(folder_nesi, "E205_erp_P1.RData")
  save(df.erp.P1.E2, file = output.erp.P1.E2)
}

# the structure of this dataset
head(df.erp.P1.E2, 10)
```


#### The maximal model
```{r maximal lmm for P1 E2}
file.max.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_max.RData")

# fit the maximal model
if (!file.exists(file.max.P1.E2)) {
  lmm.max.P1.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere +
                          (1 + Type_C + Cate_C + Dura_C + Hemi_C +
                             Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                             Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi +
                             Type_Cate_Dura_Hemi
                           | SubjCode) +
                          (1 + Type_C + Dura_C + Hemi_C +
                             Type_Dura + Type_Hemi + Dura_Hemi +
                             Type_Dura_Hemi
                           | Stimuli),
                        data = df.erp.P1.E2,
                        verbose = TRUE,
                        control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                              optCtrl = list(maxfun = 1e7)))
} else {
  load(file.max.P1.E2)
}

print(summary(lmm.max.P1.E2), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r zcp lmm for P1 E2}
file.zcp.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file.zcp.P1.E2)) {
  lmm.zcp.P1.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere + 
                          (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                             Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                             Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi + 
                             Type_Cate_Dura_Hemi
                           || SubjCode) +
                          (1 + Type_C + Dura_C + Hemi_C + 
                             Type_Dura + Type_Hemi + Dura_Hemi +
                             Type_Dura_Hemi 
                           || Stimuli),
                        data = df.erp.P1.E2,
                        verbose = TRUE,
                        control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                              optCtrl = list(maxfun = 1e7)))
} else {
  load(file.zcp.P1.E2)
}

print(summary(lmm.zcp.P1.E2), corr = FALSE)

```


#### The reduced model
```{r PCA analysis for zcp lmm for E2 P1}
summary(rePCA(lmm.zcp.P1.E2))
```


```{r }

file.rdc.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file.rdc.P1.E2)) {
  # lmm.rdc.P1.E2.step <- step(lmm.rdc.P1.E2, reduce.fixed = FALSE)
  
  lmm.rdc.P1.E2 <- update(lmm.zcp.P1.E2,
                          formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                               Type_Cate + Type_Dura + Cate_Dura + Dura_Hemi
                             || SubjCode) +
                            (1 + Type_C + Dura_C +
                               Type_Dura 
                             || Stimuli))
  
} else {
  load(file.rdc.P1.E2)
}

print(summary(lmm.rdc.P1.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.P1.E2, lmm.zcp.P1.E2, refit = FALSE)
```

#### The extended model
```{r }

file.etd.P1.E2 <- file.path(folder_nesi, "E205_P1_lmm_etd.RData")

# fit the etd model
if (!file.exists(file.etd.P1.E2)) {
  
  lmm.etd.P1.E2 <- update(lmm.rdc.P1.E2,
                          formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                               Type_Cate + Type_Dura + Cate_Dura + Dura_Hemi
                             | SubjCode) +
                            (1 + Type_C + Dura_C + 
                               Type_Dura
                             | Stimuli))
  
  lmm.etd.P1.E2.2 <- re_fit(lmm.etd.P1.E2)
  
} else {
  load(file.etd.P1.E2)
}

print(summary(lmm.etd.P1.E2.2), corr = FALSE)

```

```{r}
anova(lmm.etd.P1.E2.2, lmm.rdc.P1.E2, refit = FALSE)
```

The reduced model (`lmm.rdc.P1.E2`) explained the data better than the extended model (`lmm.rdc.P1.E2.2`).

#### The optimal model
```{r }

lmm.opt.P1.E205 <- lmm.rdc.P1.E2

# print(summary(lmm.opt.P1.E2), corr = FALSE)

summary(lmm.opt.P1.E205)

# confint(lmm.opt.P1.E205, method="Wald")
```

#### Diagnostic plots
```{r qqplot for lmm.opt.P1.E205}
# qqplot
qqplot_lmer(lmm.opt.P1.E205)
```

#### Estimated marginal means
```{r}
emm.P1.E205 <- emmeans(lmm.opt.P1.E205, ~ Type + Hemisphere + Category + Duration)

emm.P1.E205 %>% 
  as.data.frame() %>% 
  arrange(Type, Hemisphere, Category, Duration)

```


#### Plots
```{r}
# emmip(emm.P1.E205, Category ~ Duration | Type + Hemisphere, CIs = TRUE)
```

```{r p1.all.LinePlot fig.asp=1, fig.width = 4}

hemiLabel <- c("left", "right")
names(hemiLabel) <- c("Left", "Right")

p1.all.LinePlot = {
  ggplot(data = data.frame(emm.P1.E205), aes(y = emmean, x = Duration, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(Type ~ Hemisphere, # switch = "x", 
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration (ms)", y = expression(paste("P1 Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme 
}

# p1.all.LinePlot.slide <- {
#   p1.all.LinePlot + 
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('P1_all.png', p1.all.LinePlot.slide, width = 7, height = 4)


p1.all.LinePlot
```


```{r eval=FALSE, include=FALSE, fig.asp=5/6, fig.width = 6}
library(RColorBrewer)
duration_color <- c(brewer.pal(9, 'Blues')[c(6:8)], brewer.pal(12, "Paired")[6]) 
category_color <- brewer.pal(8, 'Dark2')[c(6,1)]

p1_all_LinePlot <- {
  ggplot(data = data.frame(emm.P1.E205), aes(y = emmean, x = Duration, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(aes(fill = Duration), size=4, shape=21, stroke=0) +
    scale_fill_manual(values = duration_color[c(3, 4)], guide = FALSE) +
    geom_line(aes(linetype = Category, color = Category),  size = .85) +  # position = "dodge", alpha = .7
    scale_color_manual(values=category_color, limits = c("face", "house")) +
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(Type ~ Hemisphere, # switch = "x", 
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration (ms)", y = expression(paste("P1 Amplitudes (", mu, "V)")), color = "Category", linetype = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme +
    theme(
      legend.position = c(.5, .5),
      legend.title=element_text(size=10), 
      legend.text=element_text(size=10),
    ) +
    guides(linetype = guide_legend(title.position = "left", nrow = 1),
           color = guide_legend(title.position = "left", nrow = 1))
}

ggsave('P1_all_pub.png', p1_all_LinePlot, width = 6, height = 5)
```


#### Contrasts
##### Main results for intact stimuli
Comparisons of P1 amplitudes for intact faces with different durations:
```{r P1 amplitudes for all}
contra_all_P1 <- contrast(emmeans(lmm.opt.P1.E205, ~ Duration | Hemisphere + Category + Type), 
                              "pairwise", combine = TRUE, adjust = "Bonferroni", infer = TRUE)

contra_all_P1[1:2]
summary(contra_all_P1[1:2], delta = delta_null, level = .9)
summary(contra_all_P1[1:2], delta = delta_null, side = ">")
summary(contra_all_P1[1:2], delta = delta_null, side = "<")
```

Comparisons of face-specific P1 amplitude components for intact stimuli with different durations:
```{r}
contra_all_P1_spec <- contrast(emmeans(lmm.opt.P1.E205, ~ Category + Duration | Hemisphere + Type), 
                               interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)
contra_all_P1_spec[1:2]
summary(contra_all_P1_spec[1:2], delta = delta_null, level = .9)
summary(contra_all_P1_spec[1:2], delta = delta_null, side = ">")
summary(contra_all_P1_spec[1:2], delta = delta_null, side = "<")
```

##### Main results for scrambled stimuli
Comparisons of P1 amplitudes for scrambled faces with different durations:
```{r P1 amplitudes for all scrambled}
contra_all_P1[5:6]
summary(contra_all_P1[5:6], delta = delta_null, level = .9)
summary(contra_all_P1[5:6], delta = delta_null, side = ">")
summary(contra_all_P1[5:6], delta = delta_null, side = "<")
```

Comparisons of face-specific P1 amplitude components for scrambled stimuli with different durations:
```{r}
contra_all_P1_spec[3:4]
summary(contra_all_P1_spec[3:4], delta = delta_null, level = .9)
summary(contra_all_P1_spec[3:4], delta = delta_null, side = ">")
summary(contra_all_P1_spec[3:4], delta = delta_null, side = "<")
```

##### Other results
Comparisons of P1 amplitudes between Durations (without multiple comparison corrections):
```{r}
summary(contra_all_P1[1:8], adjust = "none")
summary(contra_all_P1[1:8], delta = delta_null, side = "two.sided", adjust = "none")
```

Comparisons of face-specific P1 amplitude components between Durations (without multiple comparison corrections):
```{r}
summary(contra_all_P1_spec[1:4], adjust = "none")
summary(contra_all_P1_spec[1:4], delta = delta_null, side = "two.sided", adjust = "none")
```

### Ampitudes of the N170
```{r erp df for the N170 E2}
# only keep the data for amplitudes of the N170 (all erps)
df.erp.N170.E2 <- {
  df.erp.E2.all %>% 
    filter(Component == "N170") 
}

if (saveCSV) {
  output.erp.N170.E2 <- file.path(folder_nesi, "E205_erp_N170.RData")
  save(df.erp.N170.E2, file = output.erp.N170.E2)
}

# the structure of this dataset
head(df.erp.N170.E2, 10)
```

#### The maximal model
```{r maximal lmm for E2 N170}
file.max.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_max.RData")

# fit the maximal model
if (!file.exists(file.max.N170.E2)) {
  lmm.max.N170.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere +
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +
                               Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                               Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi +
                               Type_Cate_Dura_Hemi
                             | SubjCode) +
                            (1 + Type_C + Dura_C + Hemi_C +
                               Type_Dura + Type_Hemi + Dura_Hemi +
                               Type_Dura_Hemi
                             | Stimuli),
                          data = df.erp.N170.E2,
                          verbose = TRUE,
                          control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                optCtrl = list(maxfun = 1e7)))
} else {
  load(file.max.N170.E2)
}

print(summary(lmm.max.N170.E2), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r zcp lmm for E2 N170}

file.zcp.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file.zcp.N170.E2)) {
  lmm.zcp.N170.E2 <- lmer(MeanAmp ~ Type * Category * Duration * Hemisphere + 
                            (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                               Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                               Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi + Cate_Dura_Hemi + 
                               Type_Cate_Dura_Hemi 
                             || SubjCode) +
                            (1 + Type_C + Dura_C + Hemi_C + 
                               Type_Dura + Type_Hemi + Dura_Hemi +
                               Type_Dura_Hemi 
                             || Stimuli),
                          data = df.erp.N170.E2,
                          verbose = TRUE,
                          control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                optCtrl = list(maxfun = 1e7)))
  
} else {
  load(file.zcp.N170.E2)
}


print(summary(lmm.zcp.N170.E2), corr = FALSE)

```


#### The reduced model
```{r PCA analysis for zcp lmm for E2 N170}

summary(rePCA(lmm.zcp.N170.E2))
```


```{r}

file.rdc.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file.rdc.N170.E2)) {
  # lmm.rdc.N170.E2.step <- step(lmm.rdc.N170.E2, reduce.fixed = FALSE)
  
  lmm.rdc.N170.E2 <- update(lmm.zcp.N170.E2,
                            formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                              (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                                 Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                                 Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi
                               || SubjCode) +
                              (1 + Type_C + Dura_C + 
                                 Type_Dura
                               || Stimuli))
  
} else {
  load(file.rdc.N170.E2)
}

print(summary(lmm.rdc.N170.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.N170.E2, lmm.zcp.N170.E2, refit = FALSE)
```

#### The extended model
```{r }

file.etd.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd.RData")

# fit the etd model
if (!file.exists(file.etd.N170.E2)) {
  
  lmm.etd.N170.E2 <- update(lmm.rdc.N170.E2,
                            formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                              (1 + Type_C + Cate_C + Dura_C + Hemi_C +  
                                 Type_Cate + Type_Dura + Cate_Dura + Type_Hemi + Cate_Hemi + Dura_Hemi +
                                 Type_Cate_Dura + Type_Cate_Hemi + Type_Dura_Hemi
                               | SubjCode) +
                              (1 + Type_C + Dura_C + 
                                 Type_Dura
                               | Stimuli))
  
} else {
  load(file.etd.N170.E2)
}

print(summary(lmm.etd.N170.E2), corr = FALSE)

```

```{r}
summary(rePCA(lmm.etd.N170.E2))
```

```{r }

file.etd1.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file.etd1.N170.E2)) {
  
  lmm.etd1.N170.E2 <- update(lmm.etd.N170.E2,
                             formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                               (1 + Type_C + Dura_C + Hemi_C +  
                                  Type_Cate + Type_Dura + Type_Hemi + Dura_Hemi +
                                  Type_Cate_Dura + Type_Cate_Hemi
                                | SubjCode) +
                               (1 + Type_C + Dura_C + 
                                  Type_Dura
                                | Stimuli))
  
} else {
  load(file.etd1.N170.E2)
}

print(summary(lmm.etd1.N170.E2), corr = FALSE)

```


```{r}
summary(rePCA(lmm.etd1.N170.E2))
```


```{r }

file.etd2.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file.etd2.N170.E2)) {
  
  lmm.etd2.N170.E2 <- update(lmm.etd1.N170.E2,
                             formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                               (1 + Type_C + Dura_C + Hemi_C +  
                                  Type_Cate + Type_Dura + Dura_Hemi +
                                  Type_Cate_Dura + Type_Cate_Hemi
                                | SubjCode) +
                               (1 + Type_C + Dura_C + 
                                  Type_Dura
                                | Stimuli))
  
} else {
  load(file.etd2.N170.E2)
}

print(summary(lmm.etd2.N170.E2), corr = FALSE)

```

```{r}
summary(rePCA(lmm.etd2.N170.E2))
```


```{r }

file.etd3.N170.E2 <- file.path(folder_nesi, "E205_N170_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file.etd3.N170.E2)) {
  
  lmm.etd3.N170.E2 <- update(lmm.etd2.N170.E2,
                             formula = MeanAmp ~ Type * Category * Duration * Hemisphere + 
                               (1 + Dura_C + Hemi_C +  
                                  Type_Cate + Type_Dura + Dura_Hemi +
                                  Type_Cate_Dura + Type_Cate_Hemi
                                | SubjCode) +
                               (0 + Type_C + Dura_C + 
                                  Type_Dura
                                | Stimuli))
  
} else {
  load(file.etd3.N170.E2)
}

print(summary(lmm.etd3.N170.E2), corr = FALSE)

```


```{r}
anova(lmm.etd3.N170.E2, lmm.rdc.N170.E2, refit = FALSE)
```

#### The optimal model
```{r }

lmm.opt.N170.E205 <- lmm.rdc.N170.E2

print(summary(lmm.opt.N170.E205), corr = FALSE)

```


#### Diagnostic plots
```{r qqplot for lmm.opt.N170.E2}
# qqplot
qqplot_lmer(lmm.opt.N170.E205)
```

#### Estimated marginal means
```{r}
emm.N170.E205 <- emmeans(lmm.opt.N170.E205,  ~ Type + Hemisphere + Category + Duration)

emm.N170.E205 %>% 
  as.data.frame() %>% 
  arrange(Type, Hemisphere, Category, Duration)
  
```


#### Plots
```{r}
# emmip(emm.N170.E205, Category ~ Duration | Type + Hemisphere, CIs = TRUE) + 
#   scale_y_continuous(trans = "reverse")

```

```{r n170.all.LinePlot}

n170.all.LinePlot = {
  ggplot(data = data.frame(emm.N170.E205), aes(y = emmean, x = Duration, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(Type ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration (ms)", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme 
}

# n170.all.LinePlot.slide <- {
#   n170.all.LinePlot + 
#     scale_y_reverse(limits = c(0.8, -4.8), breaks = seq(0, -4, -1)) +  # set the limit for y axis
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('N170_all.png', n170.all.LinePlot.slide, width = 7, height = 4)

n170.all.LinePlot
```

```{r eval=FALSE, include=FALSE, fig.asp=5/6, fig.width = 6}

n170_all_LinePlot <- {
  ggplot(data = data.frame(emm.N170.E205), aes(y = emmean, x = Duration, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(aes(fill = Duration), size=4, shape=21, stroke=0) +
    scale_fill_manual(values = duration_color[c(3, 4)], guide = FALSE) +
    geom_line(aes(linetype = Category, color = Category),  size = .85) +  # position = "dodge", alpha = .7
    scale_color_manual(values=category_color, limits = c("face", "house")) +
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(Type ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration (ms)", y = expression(paste("N170 Amplitudes (", mu, "V)")), color = "Category", linetype = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme +
    theme(
      legend.position = c(.5, .5),
      legend.title=element_text(size=10), 
      legend.text=element_text(size=10),
    ) +
    guides(linetype = guide_legend(title.position = "left", nrow = 1),
           color = guide_legend(title.position = "left", nrow = 1))
}

ggsave('N170_all_pub.png', n170_all_LinePlot, width = 6, height = 5)

```




#### Contrasts
##### Main results for intact stimuli
Comparisons of N170 amplitudes for intact faces with different durations:
```{r}
contra_all_N170 <- contrast(emmeans(lmm.opt.N170.E205,  ~ Duration | Hemisphere + Category + Type),
                            "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_all_N170[1:2]
summary(contra_all_N170[1:2], delta = delta_null, level = .9)
summary(contra_all_N170[1:2], delta = delta_null, side = ">")
summary(contra_all_N170[1:2], delta = delta_null, side = "<")
```

Comparisons of N170 amplitude lateralization for intact faces with different durations:
```{r}
contra_all_N170_hemi <- contrast(emmeans(lmm.opt.N170.E205, ~ Duration + Hemisphere | Category + Type), 
                                 interaction = "pairwise", infer = TRUE)
contra_all_N170_hemi[1]
summary(contra_all_N170_hemi[1], delta = delta_null, level = .9)
summary(contra_all_N170_hemi[1], delta = delta_null, side = ">")
summary(contra_all_N170_hemi[1], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude components for intact stimuli with different durations:
```{r}
contra_all_N170_spec <- contrast(emmeans(lmm.opt.N170.E205, ~ Category + Duration | Hemisphere + Type), 
                                 interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_all_N170_spec[1:2]
summary(contra_all_N170_spec[1:2], delta = delta_null, level = .9)
summary(contra_all_N170_spec[1:2], delta = delta_null, side = ">")
summary(contra_all_N170_spec[1:2], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude component lateralization for intact stimuli with different durations:
```{r}
contra_all_N170_spec_hemi <- contrast(emmeans(lmm.opt.N170.E205, ~ Category + Duration + Hemisphere | Type), 
                                 interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_all_N170_spec_hemi[1]
summary(contra_all_N170_spec_hemi[1], delta = delta_null, level = .9)
summary(contra_all_N170_spec_hemi[1], delta = delta_null, side = ">")
summary(contra_all_N170_spec_hemi[1], delta = delta_null, side = "<")
```

##### Main results for scrambled stimuli
Comparisons of N170 amplitudes for scrambled faces with different durations:
```{r}
contra_all_N170[5:6]
summary(contra_all_N170[5:6], delta = delta_null, level = .9)
summary(contra_all_N170[5:6], delta = delta_null, side = ">")
summary(contra_all_N170[5:6], delta = delta_null, side = "<")
```

Comparisons of N170 amplitude lateralization for scrambled faces with different durations:
```{r}
contra_all_N170_hemi[3]
summary(contra_all_N170_hemi[3], delta = delta_null, level = .9)
summary(contra_all_N170_hemi[3], delta = delta_null, side = ">")
summary(contra_all_N170_hemi[3], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude components for scrambled stimuli with different durations:
```{r}
contra_all_N170_spec[3:4]
summary(contra_all_N170_spec[3:4], delta = delta_null, level = .9)
summary(contra_all_N170_spec[3:4], delta = delta_null, side = ">")
summary(contra_all_N170_spec[3:4], delta = delta_null, side = "<")
```

##### Other results
Comparisons of N170 amplitudes between Durations (without multiple comparison corrections):
```{r}
summary(contra_all_N170[1:8], adjust = "none")
summary(contra_all_N170[1:8], delta = delta_null, level = .9, adjust = "none")
```

Comparisons of N170 amplitude lateralization between Durations (without multiple comparison corrections):
```{r}
summary(contra_all_N170_hemi[1:4], adjust = "none")
summary(contra_all_N170_hemi[1:4], delta = delta_null, level = .9)
```

Comparisons of face-specific N170 amplitudes between Durations (without multiple comparison corrections):
```{r}
summary(contra_all_N170_spec[1:4], adjust = "none")
summary(contra_all_N170_spec[1:4], delta = delta_null, level = .9, adjust = "none")
```

## Linear mixed model with subjective confidence

### Converting response to subjective confidence
```{r}
df.erp.SC.E2 <- {
  df.erp.E2 %>% 
    filter(Type == "intact") %>%  # only keep the intact trials
    mutate(Confidence = if_else(Response %in% c("11", "55"), "high", 
                                if_else(Response %in% c("12", "54"), "low",
                                        if_else(substring(Response, 2) == "3", "guess", "NA"))),
           DuraConf = paste(Duration, Confidence, sep = "_")) %>% 
    filter(Confidence != "NA",
           !(DuraConf %in% c("200_guess", "200_low"))) %>% 
    mutate(Confidence = as.factor(Confidence),
           DuraConf = as.factor(DuraConf))
}
```


### Set the successive difference coding
```{r set the successive difference coding for ERP data E2 SC}
# successive difference coding
df.erp.SC.E2 <- sdif_coding_E205_erp(df.erp.SC.E2)
```

### Amplitudes of the P1
```{r erp df for the P1 E2 SC}
# only keep the data for amplitudes of the P1 (correct and incorrect erps)
df.erp.P1.SC.E2 <- {
  df.erp.SC.E2 %>% 
    filter(Component == "P1") 
}

if (saveCSV) {
  output.erp.P1.SC.E2 <- file.path(folder_nesi, "E205_erp_P1_SC.RData")
  save(df.erp.P1.SC.E2, file = output.erp.P1.SC.E2)
}

# the structure of this dataset
head(df.erp.P1.SC.E2, 10)
```


#### The maximal model
```{r maximal lmm for P1 E2 SC}

lmm.max.P1.SC.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraConf +
                           (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                           (1 + Hemi_C | Stimuli),
                         data = df.erp.P1.SC.E2,
                         verbose = TRUE,
                         control = lmerControl(optimizer = "bobyqa"))  # nloptwrap Nelder_Mead

print(summary(lmm.max.P1.SC.E2), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r zcp lmm for P1 E2 SC}

lmm.zcp.P1.SC.E2 <- update(lmm.max.P1.SC.E2,
                           formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                             (1 + Hemi_C || Stimuli))

print(summary(lmm.zcp.P1.SC.E2), corr = FALSE)

```


#### The reduced model
```{r PCA analysis for zcp lmm for E2 P1 SC}
summary(rePCA(lmm.zcp.P1.SC.E2))
```


```{r }

lmm.rdc.P1.SC.E2 <- update(lmm.zcp.P1.SC.E2,
                           formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C || SubjCode) +
                             (1 | Stimuli))


print(summary(lmm.rdc.P1.SC.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.P1.SC.E2, lmm.zcp.P1.SC.E2, refit = FALSE)
```


#### The extended model
```{r }


lmm.etd.P1.SC.E2 <- update(lmm.rdc.P1.SC.E2,
                           formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C | SubjCode) +
                             (1 | Stimuli))


print(summary(lmm.etd.P1.SC.E2), corr = FALSE)

```


```{r}
anova(lmm.rdc.P1.SC.E2, lmm.etd.P1.SC.E2, refit = FALSE)
```

#### The optimal model
```{r }

lmm.opt.P1.SC.E205 <- lmm.etd.P1.SC.E2

# print(summary(lmm.opt.P1.SC.E2), corr = FALSE)
summary(lmm.opt.P1.SC.E205)

confint(lmm.opt.P1.SC.E205, method = "Wald")

anova(lmm.opt.P1.SC.E205)

```


#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.P1.SC.E205)
```


#### Estimated marginal means
```{r}
emm.P1.SC.E205 <- emmeans(lmm.opt.P1.SC.E205, ~ Category + DuraConf + Hemisphere)

emm.P1.SC.E205 %>% 
  as_tibble() %>% 
  arrange(Category, DuraConf)
```

#### Plots
```{r}
# emmip(emm.P1.SC.E205, Category ~ DuraConf | Hemisphere, CIs = TRUE)
```

```{r p1.conf.LinePlot}

duraconf.labels = c("17ms\nguess", "17ms\nlow", "17ms\nhigh", "200ms\nhigh")

p1.conf.LinePlot = {
  ggplot(data = data.frame(emm.P1.SC.E205), aes(y = emmean, x = DuraConf, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    scale_x_discrete(labels = duraconf.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# p1.conf.LinePlot.slide <- {
#   p1.conf.LinePlot + 
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('P1_conf.png', p1.conf.LinePlot.slide, width = 8.5, height = 4)

p1.conf.LinePlot
```

```{r eval=FALSE, include=FALSE, fig.asp=5/6, fig.width = 6}

duration_color <- c(brewer.pal(9, 'Blues')[c(6, 7, 9)], brewer.pal(12, "Paired")[6]) 
category_color <- brewer.pal(8, 'Dark2')[c(6,1)]

p1_con_LinePlot = {
  ggplot(data = data.frame(emm.P1.SC.E205), aes(y = emmean, x = DuraConf, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(aes(fill = DuraConf), size=4, shape=21, stroke=0) +
    scale_fill_manual(values = duration_color, guide = FALSE) +
    geom_line(aes(linetype = Category, color = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_color_manual(values=category_color) +
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    scale_x_discrete(labels = duraconf.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("P1 Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    theme_bw() +
    erp_theme + 
    theme(
      axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)),
      legend.margin = margin(t = -10),
      legend.title=element_text(size=12), 
      legend.text=element_text(size=12),
    )
}

ggsave('P1_con_pub.png', p1_con_LinePlot, width = 7, height = 5)
```


#### Contrast
##### Main results
Comparisons of P1 amplitudes for (intact) faces with different durations and confidence (left hemisphere):
```{r P1 amplitudes for SC}
contra_SC_P1 <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ DuraConf | Hemisphere + Category), # 
                             "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_SC_P1[1:6]
summary(contra_SC_P1[1:6], delta = delta_null, level = .9)
summary(contra_SC_P1[1:6], delta = delta_null, side = ">")
summary(contra_SC_P1[1:6], delta = delta_null, side = "<")
```

Comparisons of P1 amplitudes for (intact) faces with different durations and confidence (right hemisphere):
```{r}
contra_SC_P1[7:12]
summary(contra_SC_P1[7:12], delta = delta_null, level = .9)
summary(contra_SC_P1[7:12], delta = delta_null, side = ">")
summary(contra_SC_P1[7:12], delta = delta_null, side = "<")
```

```{r eval=FALSE, include=FALSE}
# Comparisons of P1 amplitude lateralization for (intact) faces with different durations and confidence:
contra_SC_P1_hemi <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ DuraConf + Hemisphere | Category), # 
                                  interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)
contra_SC_P1_hemi[1:6]
summary(contra_SC_P1_hemi[1:6], delta = delta_null, level = .9)
summary(contra_SC_P1_hemi[1:6], delta = delta_null, side = ">")
summary(contra_SC_P1_hemi[1:6], delta = delta_null, side = "<")
```

Comparisons of face-specific P1 amplitude components for different durations and confidence (left hemisphere):
```{r}
contra_SC_P1_spec <- contrast(emmeans(lmm.opt.P1.SC.E205, ~ Category + DuraConf | Hemisphere), # 
                              interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_SC_P1_spec[1:6]
summary(contra_SC_P1_spec[1:6], delta = delta_null, level = .9)
summary(contra_SC_P1_spec[1:6], delta = delta_null, side = ">")
summary(contra_SC_P1_spec[1:6], delta = delta_null, side = "<")
```

Comparisons of face-specific P1 amplitude components for different durations and confidence (right hemisphere):
```{r}
contra_SC_P1_spec[7:12]
summary(contra_SC_P1_spec[7:12], delta = delta_null, level = .9)
summary(contra_SC_P1_spec[7:12], delta = delta_null, side = ">")
summary(contra_SC_P1_spec[7:12], delta = delta_null, side = "<")
```

##### Other results
Comparisons of P1 amplitudes for (intact) faces with different durations and confidence (without multiple comparison corrections):
```{r}
summary(contra_SC_P1[1:24], adjust = "none")
summary(contra_SC_P1[1:24], adjust = "none", delta = delta_null, level = .9)
```

### Ampitudes of the N170
```{r erp df for the N170 E2 SC}
# only keep the data for amplitudes of the N170 (all erps)
df.erp.N170.SC.E2 <- {
  df.erp.SC.E2 %>% 
    filter(Component == "N170") 
}

if (saveCSV) {
  output.erp.N170.SC.E2 <- file.path(folder_nesi, "E205_erp_N170_SC.RData")
  save(df.erp.N170.SC.E2, file = output.erp.N170.SC.E2)
}

# the structure of this dataset
head(df.erp.N170.SC.E2, 10)
```


#### The maximal model
```{r maximal lmm for E2 N170 SC}

lmm.max.N170.SC.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraConf +
                             (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                             (1 + Hemi_C | Stimuli),
                           data = df.erp.N170.SC.E2,
                           verbose = TRUE,
                           control = lmerControl(optimizer = "bobyqa"))  # nloptwrap Nelder_Mead

print(summary(lmm.max.N170.SC.E2), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r zcp lmm for E2 N170 SC}


lmm.zcp.N170.SC.E2 <- update(lmm.max.N170.SC.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                               (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                               (1 + Hemi_C || Stimuli))


print(summary(lmm.zcp.N170.SC.E2), corr = FALSE)

```

```{r compare max and zcp E2 N170 SC}
anova(lmm.max.N170.SC.E2, lmm.zcp.N170.SC.E2, refit = FALSE)
```

#### The reduced model
```{r PCA analysis for zcp lmm for E2 N170 SC}
summary(rePCA(lmm.zcp.N170.SC.E2))
```


```{r}

lmm.rdc.N170.SC.E2 <- update(lmm.zcp.N170.SC.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                               (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                               (1 | Stimuli))


print(summary(lmm.rdc.N170.SC.E2), corr = FALSE)

```


```{r}
anova(lmm.rdc.N170.SC.E2, lmm.zcp.N170.SC.E2, refit = FALSE)
```

#### The extended model
```{r}

lmm.etd.N170.SC.E2 <- update(lmm.rdc.N170.SC.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraConf +
                               (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                               (1 | Stimuli))


print(summary(lmm.rdc.N170.SC.E2), corr = FALSE)

```

```{r}
anova(lmm.rdc.N170.SC.E2, lmm.etd.N170.SC.E2, refit = FALSE)
```

#### The optimal model
```{r }

lmm.opt.N170.SC.E205 <- lmm.etd.N170.SC.E2

print(summary(lmm.opt.N170.SC.E205), corr = FALSE)

anova(lmm.opt.N170.SC.E205)
```

#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.N170.SC.E205)
```

#### Estimated marginal means
```{r}
emm.N170.SC.E205 <- emmeans(lmm.opt.N170.SC.E205, ~ Category + DuraConf + Hemisphere)

emm.N170.SC.E205 %>% 
  as_tibble() %>% 
  arrange(Category, DuraConf)
```


#### Plots
```{r}
# emmip(emm.N170.SC.E205, Category ~ DuraConf | Hemisphere, CIs = TRUE) + 
#   scale_y_continuous(trans = "reverse")
```

```{r N170.conf.LinePlot}

duraconf.labels = c("17ms\nguess", "17ms\nlow", "17ms\nhigh", "200ms\nhigh")

n170.conf.LinePlot = {
  ggplot(data = data.frame(emm.N170.SC.E205), aes(y = emmean, x = DuraConf, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    scale_x_discrete(labels = duraconf.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# n170.conf.LinePlot.slide <- {
#   n170.conf.LinePlot + 
#     scale_y_reverse(limits = c(0.8, -4.8), breaks = seq(0, -4, -1)) +  # set the limit for y axis
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('N170_confi.png', n170.conf.LinePlot.slide, width = 8.5, height = 4)

n170.conf.LinePlot
```

```{r eval=FALSE, include=FALSE, fig.asp=5/6, fig.width = 6}

duration_color <- c(brewer.pal(9, 'Blues')[c(6, 7, 9)], brewer.pal(12, "Paired")[6]) 
category_color <- brewer.pal(8, 'Dark2')[c(6,1)]

n170_con_LinePlot = {
  ggplot(data = data.frame(emm.N170.SC.E205), aes(y = emmean, x = DuraConf, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(aes(fill = DuraConf), size=4, shape=21, stroke=0) +
    scale_fill_manual(values = duration_color, guide = FALSE) +
    geom_line(aes(linetype = Category, color = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_color_manual(values=category_color) +
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    scale_x_discrete(labels = duraconf.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("N170 Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    theme_bw() +
    erp_theme +
    theme(
      axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)),
      legend.margin = margin(t = -10),
      legend.title=element_text(size=12), 
      legend.text=element_text(size=12),
    )
}

ggsave('N170_con_pub.png', n170_con_LinePlot, width = 7, height = 5)
```

#### Contrast
##### Main results
Comparisons of N170 amplitudes for (intact) faces with different durations and confidence (left hemisphere):
```{r N170 amplitudes for SC}
contra_SC_N170 <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ DuraConf | Hemisphere + Category), # 
                               "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_SC_N170[1:6]
summary(contra_SC_N170[1:6], delta = delta_null, level = .9)
summary(contra_SC_N170[1:6], delta = delta_null, side = ">")
summary(contra_SC_N170[1:6], delta = delta_null, side = "<")
```

Comparisons of N170 amplitudes for (intact) faces with different durations and confidence (right hemisphere):
```{r}
contra_SC_N170[7:12]
summary(contra_SC_N170[7:12], delta = delta_null, level = .9)
summary(contra_SC_N170[7:12], delta = delta_null, side = ">")
summary(contra_SC_N170[7:12], delta = delta_null, side = "<")
```

Comparisons of N170 amplitude lateralization for (intact) faces with different durations and confidence:
```{r}
contra_SC_N170_hemi <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ DuraConf + Hemisphere | Category), # 
                                    interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)
contra_SC_N170_hemi[1:6]
summary(contra_SC_N170_hemi[1:6], delta = delta_null, level = .9)
summary(contra_SC_N170_hemi[1:6], delta = delta_null, side = ">")
summary(contra_SC_N170_hemi[1:6], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude components for different durations and confidence (left hemisphere):
```{r}
contra_SC_N170_spec <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ Category + DuraConf | Hemisphere), # 
                                interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_SC_N170_spec[1:6]
summary(contra_SC_N170_spec[1:6], delta = delta_null, level = .9)
summary(contra_SC_N170_spec[1:6], delta = delta_null, side = ">")
summary(contra_SC_N170_spec[1:6], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude components for different durations and confidence (right hemisphere):
```{r}
contra_SC_N170_spec[7:12]
summary(contra_SC_N170_spec[7:12], delta = delta_null, level = .9)
summary(contra_SC_N170_spec[7:12], delta = delta_null, side = ">")
summary(contra_SC_N170_spec[7:12], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude component lateralization for different durations and confidence:
```{r}
contra_SC_N170_spec_hemi <- contrast(emmeans(lmm.opt.N170.SC.E205, ~ Category + DuraConf + Hemisphere), # 
                                interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_SC_N170_spec_hemi
summary(contra_SC_N170_spec_hemi, delta = delta_null, level = .9)
summary(contra_SC_N170_spec_hemi, delta = delta_null, side = ">")
summary(contra_SC_N170_spec_hemi, delta = delta_null, side = "<")
```

##### Other results
Comparisons of N170 amplitudes for different durations and confidence (without multiple comparison corrections):
```{r}
summary(contra_SC_N170[1:24], adjust = "none")
summary(contra_SC_N170[1:24], adjust = "none", delta = delta_null, level = .9)
```

## Linear mixed model with high subjective confidences 

```{r}
tmpBlock.count <- {
  clean_beha_205 %>% 
    filter(Type == "intact") %>% 
    group_by(SubjCode, Category, Duration, blockID) %>% 
    summarize(Count_sum = n())
}

avg.resp.long.E205.Block <- {
  clean_beha_205 %>% 
    filter(Type == "intact") %>% 
    group_by(SubjCode, Category, Duration, blockID, Resp) %>% 
    summarize(Count = n()) %>% 
    
    right_join(tmpBlock.count, by = c("SubjCode", "blockID", "Category", "Duration")) %>% 
    mutate(RespRate = Count / Count_sum) %>% 
    ungroup()
}

# descriptive statistics of accuracy for plotting
desc.resp.E205.Block <- {
  avg.resp.long.E205.Block %>%
    group_by(blockID, Category, Duration, Resp) %>%
    summarize(Mean = mean(RespRate)
              , N = n()
              , SD = if_else(N > 1, sd(RespRate), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI = SE * qt(0.975,N)
              , Median = median(RespRate)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>% 
    ungroup() %>% 
    add_row(blockID = 2, Category = "house", Duration = 200, Resp = 2, Mean = 0, N = 0, SD = 0, SE = 0, SE.lo = 0,
            SE.hi = 0, CI = 0, Median = 0, Lower = 0, Upper = 0)
}

avg.resp.wide.E205.Block <- {
  avg.resp.long.E205.Block %>% 
    mutate(Conditions = paste(blockID, Category, Duration, Resp, sep = "_")) %>% 
    select(SubjCode, Conditions, RespRate) %>% 
    spread(Conditions, RespRate)
}


```

```{r}
block.high <- {
  avg.resp.long.E205.Block %>% 
    filter(Category == "face", Duration == 17, Resp == 1, SubjCode != "P513") 
}

t.test(filter(block.high, blockID == 1)$RespRate, filter(block.high, blockID == 2)$RespRate, paired = T)


```


```{r rainclound plot of the RT data E205 block, warning = FALSE}
knitr::kable(desc.resp.E205.Block, digits = 4)

rt.RainPlot.E205.Block <- {
  ggplot(data = avg.resp.long.E205.Block, aes(y = RespRate, x = as.factor(Resp), fill = Category)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RespRate, color = Category), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RespRate), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.resp.E205.Block, aes(y = Mean, x = Resp, color = Category), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.resp.E205.Block, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(Duration ~ blockID) +
    
    # facet_grid(. ~ Type, switch = "x") +  # create two panels to show data
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") + # palette = "RdBu"
    # scale_fill_brewer(palette = "Set1") + # palette = "RdBu"
    labs(title = "Reaction times for E205", x = "Stimulus Type", y = "Reaction times (ms)", fill = "Duration(ms)", color = "Duration(ms)") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot for reaction times block}
rt.RainPlot.E205.Block
```


```{r}

bloc.labels <- c("1st Half", "2nd Half")
names(bloc.labels) <- c(1, 2)

acc.ColuPlot.E205.Block <- {
  ggplot(data = desc.resp.E205.Block, aes(y = Mean, x = Resp, fill = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Duration ~ blockID,
               labeller = labeller(Duration = dura.labels,
                                   blockID = bloc.labels)) +
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "", x = "Responses", y = "Percentage", fill = "Category") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    erp_theme
}

acc.ColuPlot.E205.Block

```


```{r}
df.ratio.E205.Block <- {
  clean_beha_205 %>%
    filter(Type == "intact") %>% 
    mutate(isFace = if_else(Category == "face", 1, 0)) %>% 
    group_by(SubjCode, blockID, Duration, Resp) %>% 
    summarize(ratio = mean(isFace), Count = n())
}

desc.ratio.E205.Block <- {
  df.ratio.E205.Block %>%
    group_by(blockID, Duration, Resp) %>%
    summarize(Mean = mean(ratio)
              , N = n()
              , SD = if_else(N > 1, sd(ratio), 0)
              , SE = SD/sqrt(N)
              , SE.lo = Mean - SE, SE.hi = Mean + SE
              , CI = SE * qt(0.975,N)
              , Median = median(ratio)
              , Lower = Mean - SD, Upper = Mean + SD # for rainclound plot
    ) %>% 
    ungroup()
}

```



```{r}

ratio.ColuPlot.E205.Block <- {
  ggplot(data = desc.ratio.E205.Block, aes(y = Mean, x = Resp)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col(position = "dodge", color = "black", alpha = .7) +  # position of columns and countour of columns
    facet_grid(Duration ~ blockID,
               labeller = labeller(Duration = dura.labels,
                                   blockID = bloc.labels)) +
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5,
                  position = position_dodge(width=0.9)) +
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
    coord_cartesian(ylim = c(0,1.1)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "", x = "Responses", y = "Percentage") +  # set the names for main, x and y axises Subjective Responses for E205
    scale_fill_grey() +  # set the color for columns
    # geom_text(label = c("***", "***", "", ""), color = c("red", "red", "red", "red"), size = 6, nudge_y = 0.05, nudge_x = rep(c(-0.225, 0.225), 2)) + # add starts to the significant columns
    plot_theme
}

ratio.ColuPlot.E205.Block

```


```{r}
df.erp.high.E2 <- {
  df.erp.SC.E2 %>% 
    filter(Confidence == "high") %>% 
    mutate(DuraBlock = paste(Duration, Block_ST_table, sep = "_")) %>% 
    sdif_coding_E205_erp_conf()
}

```


### Amplitudes of the P1
```{r erp df for the P1 E2 high}
# only keep the data for amplitudes of the P1 (correct and incorrect erps)
df.erp.P1.high.E2 <- {
  df.erp.high.E2 %>% 
    filter(Component == "P1")
}

if (saveCSV) {
  output.erp.P1.high.E2 <- file.path(folder_nesi, "E205_erp_P1_high.RData")
  save(df.erp.P1.high.E2, file = output.erp.P1.high.E2)
}

# the structure of this dataset
head(df.erp.P1.high.E2, 10)
```


#### The maximal model
```{r maximal lmm for P1 E2 high}

lmm.max.P1.high.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraBlock +
                             (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                             (1 + Hemi_C | Stimuli),
                           data = df.erp.P1.high.E2,
                           verbose = TRUE,
                           control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                 optCtrl = list(maxfun = 1e5)))

print(summary(lmm.max.P1.high.E2), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r zcp lmm for P1 E2 high}

lmm.zcp.P1.high.E2 <- update(lmm.max.P1.high.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                               (1 + Hemi_C || Stimuli))


print(summary(lmm.zcp.P1.high.E2), corr = FALSE)

```


#### The reduced model
```{r}
summary(rePCA(lmm.zcp.P1.high.E2))
```


```{r}
lmm.rdc.P1.high.E2 <- update(lmm.zcp.P1.high.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C || SubjCode) +
                               (1 | Stimuli))

print(summary(lmm.rdc.P1.high.E2), corr = FALSE)
```

```{r}
anova(lmm.rdc.P1.high.E2, lmm.zcp.P1.high.E2, refit = FALSE)
```

#### The extended model

```{r}
lmm.etd.P1.high.E2 <- update(lmm.rdc.P1.high.E2,
                             formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C | SubjCode) +
                               (1 | Stimuli))

print(summary(lmm.etd.P1.high.E2), corr = FALSE)
```

```{r}
anova(lmm.etd.P1.high.E2, lmm.rdc.P1.high.E2, refit = FALSE)
```

#### The optimal model

```{r}
lmm.opt.P1.high.E205 <- lmm.etd.P1.high.E2

summary(lmm.opt.P1.high.E205)

anova(lmm.opt.P1.high.E205)
```

#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.P1.high.E205)
```



#### Estimated marginal means
```{r}
emm.P1.high.E205 <- emmeans(lmm.opt.P1.high.E205, ~ DuraBlock + Category + Hemisphere)

emm.P1.high.E205 %>% 
  as_tibble() %>% 
  arrange(DuraBlock, Category, Hemisphere)
```

#### Plots
```{r}
# emmip(emm.P1.high.E205, Category ~ DuraBlock | Hemisphere, CIs = TRUE)
```


```{r p1.high.LinePlot}

durablock.labels = c("17ms\nhalf 1", "17ms\nhalf 2", "200ms\nhalf 2")

p1.high.LinePlot = {
  ggplot(data = data.frame(emm.P1.high.E205), aes(y = emmean, x = DuraBlock, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    scale_x_discrete(labels = durablock.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# p1.high.LinePlot.slide <- {
#   p1.high.LinePlot + 
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('P1_high.png', p1.high.LinePlot.slide, width = 7.5, height = 4)

p1.high.LinePlot
```


```{r eval=FALSE, include=FALSE, fig.asp=5/6, fig.width = 6}

duration_color <- c(brewer.pal(9, 'Blues')[c(6, 8)], brewer.pal(12, "Paired")[6]) 
category_color <- brewer.pal(8, 'Dark2')[c(6,1)]

p1_high_LinePlot = {
  ggplot(data = data.frame(emm.P1.high.E205), aes(y = emmean, x = DuraBlock, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(aes(fill = DuraBlock), size=4, shape=21, stroke=0) +
    scale_fill_manual(values = duration_color, guide = FALSE) +
    geom_line(aes(linetype = Category, color = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_color_manual(values=category_color) +
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_p1) +  # set the limit for y axis
    scale_x_discrete(labels = durablock.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Blocks", y = expression(paste("P1 Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    theme_bw() +
    erp_theme +
    theme(
      axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)),
      legend.margin = margin(t = -10),
      legend.title=element_text(size=12), 
      legend.text=element_text(size=12),
    )
}

ggsave('p1_high_pub.png', p1_high_LinePlot, width = 7, height = 4.5)
```



#### Contrast
##### Main results
Comparisons of P1 amplitudes for (intact) faces with different durations and high confidence (left hemisphere):
```{r P1 amplitudes for high}
contra_high_P1 <- contrast(emmeans(lmm.opt.P1.high.E205, ~ DuraBlock | Hemisphere + Category), 
                               "pairwise", adjust = "none", infer = TRUE)

contra_high_P1[1:3]
summary(contra_high_P1[1:3], delta = delta_null, level = .9)
summary(contra_high_P1[1:3], delta = delta_null, side = ">")
summary(contra_high_P1[1:3], delta = delta_null, side = "<")
```

Comparisons of P1 amplitudes for (intact) faces with different durations and high confidence (right hemisphere):
```{r}
contra_high_P1[4:6]
summary(contra_high_P1[4:6], delta = delta_null, level = .9)
summary(contra_high_P1[4:6], delta = delta_null, side = ">")
summary(contra_high_P1[4:6], delta = delta_null, side = "<")
```

```{r eval=FALSE, include=FALSE}
# Comparisons of P1 amplitude lateralization for (intact) faces with different durations and high confidence:
contra_high_P1_hemi <- contrast(emmeans(lmm.opt.P1.high.E205, ~ DuraBlock + Hemisphere | Category), # 
                                    interaction = "pairwise", adjust = "none", infer = TRUE)
contra_high_P1_hemi[1:3]
summary(contra_SC_P1_hemi[1:3], delta = delta_null, level = .9)
summary(contra_SC_P1_hemi[1:3], delta = delta_null, side = ">")
summary(contra_SC_P1_hemi[1:3], delta = delta_null, side = "<")
```

Comparisons of face-specific P1 amplitude components for (intact) faces with different durations and high confidence (left hemisphere):
```{r}
contra_high_P1_spec <- contrast(emmeans(lmm.opt.P1.high.E205, ~ Category + DuraBlock | Hemisphere), # 
                                interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)
contra_high_P1_spec[1:3]
summary(contra_high_P1_spec[1:3], delta = delta_null, level = .9)
summary(contra_high_P1_spec[1:3], delta = delta_null, side = ">")
summary(contra_high_P1_spec[1:3], delta = delta_null, side = "<")
```

Comparisons of face-specific P1 amplitude components for (intact) faces with different durations and high confidence (right hemisphere):
```{r}
contra_high_P1_spec[4:6]
summary(contra_high_P1_spec[4:6], delta = delta_null, level = .9)
summary(contra_high_P1_spec[4:6], delta = delta_null, side = ">")
summary(contra_high_P1_spec[4:6], delta = delta_null, side = "<")
```


##### Other results
Comparisons of P1 amplitudes for different durations and high confidence (without multiple comparison corrections):
```{r}
summary(contra_high_P1[1:12], adjust = "none")
summary(contra_high_P1[1:12], adjust = "none", delta = delta_null, level = .9)
```

### Amplitudes of the N170
```{r erp df for the N170 E2 high}
# only keep the data for amplitudes of the N170 (correct and incorrect erps)
df.erp.N170.high.E2 <- {
  df.erp.high.E2 %>% 
    filter(Component == "N170")
}

if (saveCSV) {
  output.erp.N170.high.E2 <- file.path(folder_nesi, "E205_erp_N170_high.RData")
  save(df.erp.N170.high.E2, file = output.erp.N170.high.E2)
}

# the structure of this dataset
head(df.erp.N170.high.E2, 10)
```


#### The maximal model
```{r maximal lmm for N170 E2 high}

lmm.max.N170.high.E2 <- lmer(MeanAmp ~ Category * Hemisphere * DuraBlock +
                               (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                               (1 + Hemi_C | Stimuli),
                             data = df.erp.N170.high.E2,
                             verbose = TRUE,
                             control = lmerControl(optimizer = "bobyqa",  # nloptwrap Nelder_Mead
                                                   optCtrl = list(maxfun = 1e5)))

print(summary(lmm.max.N170.high.E2), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r zcp lmm for N170 E2 high}

lmm.zcp.N170.high.E2 <- update(lmm.max.N170.high.E2,
                               formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                                 (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                                 (1 + Hemi_C || Stimuli))

print(summary(lmm.zcp.N170.high.E2), corr = FALSE)

```


#### The reduced model
```{r}
summary(rePCA(lmm.zcp.N170.high.E2))
```

```{r}
lmm.rdc.N170.high.E2 <- update(lmm.zcp.N170.high.E2,
                               formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                                 (1 + Cate_C + Hemi_C + Cate_Hemi || SubjCode) +
                                 (1 | Stimuli))

print(summary(lmm.rdc.N170.high.E2), corr = FALSE)
```

```{r}
anova(lmm.rdc.N170.high.E2, lmm.zcp.N170.high.E2, refit = FALSE)
```

#### The extended model
```{r}
lmm.etd.N170.high.E2 <- update(lmm.rdc.N170.high.E2,
                               formula = MeanAmp ~ Category * Hemisphere * DuraBlock +
                                 (1 + Cate_C + Hemi_C + Cate_Hemi | SubjCode) +
                                 (1 | Stimuli))

print(summary(lmm.etd.N170.high.E2), corr = FALSE)
```

```{r}
anova(lmm.etd.N170.high.E2, lmm.rdc.N170.high.E2, refit = FALSE)
```

#### The optimal model
```{r}
lmm.opt.N170.high.E205 <- lmm.etd.N170.high.E2

summary(lmm.opt.N170.high.E205)

anova(lmm.opt.N170.high.E205)
```

#### Diagnostic plots
```{r}
qqplot_lmer(lmm.opt.N170.high.E205)
```


#### Estimated marginal means
```{r}
emm.N170.high.E205 <- emmeans(lmm.opt.N170.high.E205, ~ DuraBlock + Category + Hemisphere)

emm.N170.high.E205 %>% 
  as_tibble() %>% 
  arrange(DuraBlock, Category, Hemisphere)
```


#### Plots
```{r}
# emmip(emm.N170.high.E205, Category ~ DuraBlock | Hemisphere, CIs = TRUE) +
#   scale_y_continuous(trans = "reverse")

```


```{r n170.high.LinePlot}

n170.high.LinePlot = {
  ggplot(data = data.frame(emm.N170.high.E205), aes(y = emmean, x = DuraBlock, color = Category, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(size = 2) +
    geom_line(aes(linetype = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    scale_x_discrete(labels = durablock.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Subjective Confidence", y = expression(paste("Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    # scale_x_discrete(labels = c("left", "right")) +
    # geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    erp_theme
}

# n170.high.LinePlot.slide <- {
#   n170.high.LinePlot + 
#     scale_y_reverse(limits = c(0.8, -4.8), breaks = seq(0, -4, -1)) +  # set the limit for y axis
#     theme(legend.position="right",
#           axis.line = element_line(color="black", size = 3))
# }
# ggsave('N170_high.png', n170.high.LinePlot.slide, width = 7.5, height = 4)

n170.high.LinePlot
```

```{r eval=FALSE, include=FALSE, fig.asp=5/6, fig.width = 6}

duration_color <- c(brewer.pal(9, 'Blues')[c(6, 8)], brewer.pal(12, "Paired")[6]) 
category_color <- brewer.pal(8, 'Dark2')[c(6,1)]

n170_high_LinePlot = {
  ggplot(data = data.frame(emm.N170.high.E205), aes(y = emmean, x = DuraBlock, group = Category)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point(aes(fill = DuraBlock), size=4, shape=21, stroke=0) +
    scale_fill_manual(values = duration_color, guide = FALSE) +
    geom_line(aes(linetype = Category, color = Category), size = .85) +  # position = "dodge", alpha = .7
    scale_color_manual(values=category_color) +
    scale_linetype_manual(values=c("solid", "dashed")) +
    geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Hemisphere, # switch = "x",
               labeller = labeller(Hemisphere = hemiLabel)) +
    scale_y_reverse(limits = ylimit_n170, breaks = seq(1, -5, -1)) +  # set the limit for y axis
    scale_x_discrete(labels = durablock.labels) +
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(x = "Duration and Blocks", y = expression(paste("N170 Amplitudes (", mu, "V)")), fill = "Category") +  # set the names for main, x and y axises title = "", 
    theme_bw() +
    erp_theme +
    theme(
      axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)),
      legend.margin = margin(t = -10),
      legend.title=element_text(size=12), 
      legend.text=element_text(size=12),
    )
}

ggsave('n170_high_pub.png', n170_high_LinePlot, width = 7, height = 4.5)
```

#### Contrast
##### Main results
Comparisons of N170 amplitudes for (intact) faces with different durations and high confidence (left hemisphere):
```{r N170 amplitudes for high}
contra_high_N170 <- contrast(emmeans(lmm.opt.N170.high.E205, ~ DuraBlock | Hemisphere + Category), # 
                                 "pairwise", adjust = "Bonferroni", infer = TRUE)

# left hemisphere
contra_high_N170[1:3]
summary(contra_high_N170[1:3], delta = delta_null, level = .9)
summary(contra_high_N170[1:3], delta = delta_null, side = ">")
summary(contra_high_N170[1:3], delta = delta_null, side = "<")
```

Comparisons of N170 amplitudes for (intact) faces with different durations and high confidence (right hemisphere):
```{r}
# right hemisphere
contra_high_N170[4:6]
summary(contra_high_N170[4:6], delta = delta_null, level = .9)
summary(contra_high_N170[4:6], delta = delta_null, side = ">")
summary(contra_high_N170[4:6], delta = delta_null, side = "<")
```

Comparisons of N170 amplitude lateralization for (intact) faces with different durations and high confidence:
```{r}
contra_high_N170_hemi <- contrast(emmeans(lmm.opt.N170.high.E205, ~ DuraBlock + Hemisphere | Category), # 
                                      interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)
contra_high_N170_hemi[1:3]
summary(contra_high_N170_hemi[1:3], delta = delta_null, level = .9)
summary(contra_high_N170_hemi[1:3], delta = delta_null, side = ">")
summary(contra_high_N170_hemi[1:3], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude components for (intact) faces with different durations and high confidence (left hemisphere):
```{r}
contra_high_N170_spec <- contrast(emmeans(lmm.opt.N170.high.E205, ~ Category + DuraBlock | Hemisphere), # 
                                  interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_high_N170_spec[1:3]
summary(contra_high_N170_spec[1:3], delta = delta_null, level = .9)
summary(contra_high_N170_spec[1:3], delta = delta_null, side = ">")
summary(contra_high_N170_spec[1:3], delta = delta_null, side = "<")
```

Comparisons of face-specific N170 amplitude components for (intact) faces with different durations and high confidence (right hemisphere):
```{r}
# right
contra_high_N170_spec[4:6]
summary(contra_high_N170_spec[4:6], delta = delta_null, level = .9)
summary(contra_high_N170_spec[4:6], delta = delta_null, side = ">")
summary(contra_high_N170_spec[4:6], delta = delta_null, side = "<")

```

Comparisons of face-specific N170 amplitude component lateralization for (intact) faces with different durations and high confidence:
```{r}
contra_high_N170_spec_hemi <- contrast(emmeans(lmm.opt.N170.high.E205, ~ Category + DuraBlock + Hemisphere), # 
                                  interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_high_N170_spec_hemi
summary(contra_high_N170_spec_hemi, delta = delta_null, level = .9)
summary(contra_high_N170_spec_hemi, delta = delta_null, side = ">")
summary(contra_high_N170_spec_hemi, delta = delta_null, side = "<")
```

##### Other results
Comparisons of P1 amplitudes for different durations and high confidence (without multiple comparison corrections):
```{r}
summary(contra_high_N170[1:12], adjust = "none")
summary(contra_high_N170[1:12], delta = delta_null, adjust = "none", level = .9)
```

```{r}
contra_high_N170_spec.hemi <- contrast(emmeans(lmm.opt.N170.high.E205, ~ Category + DuraBlock + Hemisphere), # 
                                       interaction = "pairwise", adjust = "Bonferroni", infer = TRUE)

contra_high_N170_spec.hemi
summary(contra_high_N170_spec.hemi, delta = delta_null, level = .9)
```

# Appendix

## Model selection procedure

For the analysis for every dependent variable, an optimal model was obtained by the following general steps:

1. **Maximum Model**: a maximum model with all fixed and random factors was built. 
2. **ZCP Model**: a zero-correlated-parameter (zcp) model based on the maximum model is built. The only difference between zcp and maximum models is that the correlations between random effects are forced to be zero in the zcp model.
3. **Reduced Model**: the random effects which are not supported by the data will be removed from the zcp model. The function `step(fit, fixed.reduce = FALSE)` from `library(lmerTest)` is used for this step. The algorithm could be found [here](#stepfun).
4. **Extended Model**: extending the reduced model with correlation parameters between the remaining random effects.
5. **Pruning Model**: pruning low correlation parameters. (Usually I don't do this.)

More details about this whole process chould be found here: Bates, D., Kliegl, R., Vasishth, S., & Baayen, H. (2015). Parsimonious Mixed Models. Retrieved from http://arxiv.org/abs/1506.04967.

## Algorithm of function `step` {#stepfun}
The outline of the algorithm of `step(fit, reduce.fixed = false)` function is: 

>  Simplification of the random effects structure:
>
>   1. Let M be the linear mixed effects model specified by a user. 
>
>   2. If there are random effects in M then go to 3, otherwise stop. 
>
>   3. For each random effect ri in M do: 
>       (a) Create a reduced model Mi by eliminating ri from M. 
>
>       (b) Calculate pi, the p value from the likelihood ratio test of comparing M to Mi. 
>
>       (c) Save pi and Mi.
>
>   4. Find pmax; the maximum of all pi and let Mmax denote the corresponding model. 
>
>   5. Set M to Mmax. If pmax is guesser than α level then go back to 3, otherwise stop.

More deatils could be found: Kuznetsova, A., Brockhoff, P. B., & Christensen, R. H. B. (2017). lmerTest Package: Tests in Linear Mixed Effects Models. Journal of Statistical Software, 82(13), 1-26. http://doi.org/10.18637/jss.v082.i13 **Page 8**


## Stimuli specific effects
```{r}

# 28 participants in total

resp.stim <- {
  clean_beha_205 %>% 
    # filter(Duration == "17", Resp == "1") %>% 
    mutate(isKey1 = as.numeric(Resp == "1"),
           Type_Category = paste(Type, Category, sep = "-")) %>% 
    group_by(Stimuli, Duration, Type_Category) %>% 
    summarize(avgCount = mean(isKey1)) 
  
}

ggplot(resp.stim, aes(x = Stimuli, y = avgCount, fill = Type_Category)) +
  geom_col() +
  facet_grid(Duration ~ .) +
  labs(title = "Averaged percentage of being responsed as 'Key 1' for each stimuli",
       y = "Percentage") +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        text = element_text(size = 10),
        axis.title = element_text(size = 16), 
        axis.text = element_text(size = 15), # the size of the texts in plot
        # axis.text.x = element_text(angle = 45, vjust = 0.5),
        legend.title=element_text(size=16),
        legend.text=element_text(size=16),
        # legend.position = "bottom",
        legend.key.width = unit(1.2, "cm"),
        plot.title = element_text(lineheight=.8, face="bold", size = 17),
        strip.text = element_text(face="bold", size=15, lineheight=5.0),
        strip.background = element_rect(fill="white", colour="white", size=1),
        strip.placement = "outside",
        legend.position = "bottom") 
```


```{r}

resp.stim.1 <- {
  clean_beha_205 %>% 
    mutate(isKey1 = as.numeric(Resp == "1")) %>% 
    filter(Type == "intact", Category == "face") %>% 
    group_by(Stimuli, SubjCode, Duration) %>% 
    summarize(avgCount = mean(isKey1)) %>% 
    ungroup() 
}

resp.stim.1.17 <- {
  resp.stim.1 %>% 
    filter(Duration == "17") %>% 
    select(-Duration) %>% 
    spread(Stimuli, avgCount)
}

resp.stim.1.17 <- data.matrix(select(resp.stim.1.17, -SubjCode))

resp.stim.1.200 <- {
  resp.stim.1 %>% 
    filter(Duration == "200") %>% 
    select(-Duration) %>% 
    spread(Stimuli, avgCount)
}

resp.stim.1.200 <- data.matrix(select(resp.stim.1.200, -SubjCode))


library(plotly)

heatmap_17 <- plot_ly(z = data.matrix(resp.stim.1.17), type = "heatmap", name = "Figrename")
heatmap_200 <- plot_ly(z = data.matrix(resp.stim.1.200), type = "heatmap", name = "Figrename")

```

# Versions of packages used
```{r versions}
# rstudioapi::versionInfo()
sessionInfo()
```
